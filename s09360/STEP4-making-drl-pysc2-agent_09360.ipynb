{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4 - Making DRL PySC2 Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Runnning 'Agent code' on jupyter notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "### unfortunately, PySC2 uses Abseil, which treats python code as if its run like an app\n",
    "# This does not play well with jupyter notebook\n",
    "# So we will need to monkeypatch sys.argv\n",
    "\n",
    "\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS-IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"Run an agent.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "#sys.argv = [\"python\", \"--map\", \"AbyssalReef\"]\n",
    "sys.argv = [\"python\", \"--map\", \"Simple64\"]\n",
    "\n",
    "import importlib\n",
    "import threading\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from future.builtins import range  # pylint: disable=redefined-builtin\n",
    "\n",
    "from pysc2 import maps\n",
    "from pysc2.env import available_actions_printer\n",
    "from pysc2.env import run_loop\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import point_flag\n",
    "from pysc2.lib import stopwatch\n",
    "from pysc2.lib import actions\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# because of Abseil's horrible design for running code underneath Colabs\n",
    "# We have to pull out this ugly hack from the hat\n",
    "if \"flags_defined\" not in globals():\n",
    "    flags.DEFINE_bool(\"render\", False, \"Whether to render with pygame.\")\n",
    "    point_flag.DEFINE_point(\"feature_screen_size\", \"84\",\n",
    "                            \"Resolution for screen feature layers.\")\n",
    "    point_flag.DEFINE_point(\"feature_minimap_size\", \"64\",\n",
    "                            \"Resolution for minimap feature layers.\")\n",
    "    point_flag.DEFINE_point(\"rgb_screen_size\", None,\n",
    "                            \"Resolution for rendered screen.\")\n",
    "    point_flag.DEFINE_point(\"rgb_minimap_size\", None,\n",
    "                            \"Resolution for rendered minimap.\")\n",
    "    flags.DEFINE_enum(\"action_space\", \"RAW\", sc2_env.ActionSpace._member_names_,  # pylint: disable=protected-access\n",
    "                      \"Which action space to use. Needed if you take both feature \"\n",
    "                      \"and rgb observations.\")\n",
    "    flags.DEFINE_bool(\"use_feature_units\", False,\n",
    "                      \"Whether to include feature units.\")\n",
    "    flags.DEFINE_bool(\"use_raw_units\", True,\n",
    "                      \"Whether to include raw units.\")\n",
    "    flags.DEFINE_integer(\"raw_resolution\", 64, \"Raw Resolution.\")\n",
    "    flags.DEFINE_bool(\"disable_fog\", True, \"Whether to disable Fog of War.\")\n",
    "\n",
    "    flags.DEFINE_integer(\"max_agent_steps\", 0, \"Total agent steps.\")\n",
    "    flags.DEFINE_integer(\"game_steps_per_episode\", None, \"Game steps per episode.\")\n",
    "    flags.DEFINE_integer(\"max_episodes\", 0, \"Total episodes.\")\n",
    "    flags.DEFINE_integer(\"step_mul\", 8, \"Game steps per agent step.\")\n",
    "    flags.DEFINE_float(\"fps\", 22.4, \"Frames per second to run the game.\")\n",
    "\n",
    "    #flags.DEFINE_string(\"agent\", \"sc2.agent.BasicAgent.ZergBasicAgent\",\n",
    "    #                    \"Which agent to run, as a python path to an Agent class.\")\n",
    "    #flags.DEFINE_enum(\"agent_race\", \"zerg\", sc2_env.Race._member_names_,  # pylint: disable=protected-access\n",
    "    #                  \"Agent 1's race.\")\n",
    "    flags.DEFINE_string(\"agent\", \"TerranRLAgentWithRawActsAndRawObs\",\n",
    "                        \"Which agent to run, as a python path to an Agent class.\")\n",
    "    flags.DEFINE_enum(\"agent_race\", \"terran\", sc2_env.Race._member_names_,  # pylint: disable=protected-access\n",
    "                      \"Agent 1's race.\")\n",
    "\n",
    "    flags.DEFINE_string(\"agent2\", \"Bot\", \"Second agent, either Bot or agent class.\")\n",
    "    flags.DEFINE_enum(\"agent2_race\", \"terran\", sc2_env.Race._member_names_,  # pylint: disable=protected-access\n",
    "                      \"Agent 2's race.\")\n",
    "    flags.DEFINE_enum(\"difficulty\", \"easy\", sc2_env.Difficulty._member_names_,  # pylint: disable=protected-access\n",
    "                      \"If agent2 is a built-in Bot, it's strength.\")\n",
    "\n",
    "    flags.DEFINE_bool(\"profile\", False, \"Whether to turn on code profiling.\")\n",
    "    flags.DEFINE_bool(\"trace\", False, \"Whether to trace the code execution.\")\n",
    "    flags.DEFINE_integer(\"parallel\", 1, \"How many instances to run in parallel.\")\n",
    "\n",
    "    flags.DEFINE_bool(\"save_replay\", True, \"Whether to save a replay at the end.\")\n",
    "\n",
    "    flags.DEFINE_string(\"map\", None, \"Name of a map to use.\")\n",
    "    flags.mark_flag_as_required(\"map\")\n",
    "\n",
    "flags_defined = True\n",
    "\n",
    "def run_thread(agent_classes, players, map_name, visualize):\n",
    "  \"\"\"Run one thread worth of the environment with agents.\"\"\"\n",
    "  with sc2_env.SC2Env(\n",
    "      map_name=map_name,\n",
    "      players=players,\n",
    "      agent_interface_format=sc2_env.parse_agent_interface_format(\n",
    "        feature_screen=FLAGS.feature_screen_size,\n",
    "        feature_minimap=FLAGS.feature_minimap_size,\n",
    "        rgb_screen=FLAGS.rgb_screen_size,\n",
    "        rgb_minimap=FLAGS.rgb_minimap_size,\n",
    "        action_space=FLAGS.action_space,\n",
    "        use_raw_units=FLAGS.use_raw_units,\n",
    "        raw_resolution=FLAGS.raw_resolution),\n",
    "      step_mul=FLAGS.step_mul,\n",
    "      game_steps_per_episode=FLAGS.game_steps_per_episode,\n",
    "      disable_fog=FLAGS.disable_fog,\n",
    "      visualize=visualize) as env:\n",
    "    #env = available_actions_printer.AvailableActionsPrinter(env)\n",
    "    agents = [agent_cls() for agent_cls in agent_classes]\n",
    "    run_loop.run_loop(agents, env, FLAGS.max_agent_steps, FLAGS.max_episodes)\n",
    "    if FLAGS.save_replay:\n",
    "      env.save_replay(agent_classes[0].__name__)\n",
    "\n",
    "def main(unused_argv):\n",
    "  \"\"\"Run an agent.\"\"\"\n",
    "  #stopwatch.sw.enabled = FLAGS.profile or FLAGS.trace\n",
    "  #stopwatch.sw.trace = FLAGS.trace\n",
    "\n",
    "  map_inst = maps.get(FLAGS.map)\n",
    "\n",
    "  agent_classes = []\n",
    "  players = []\n",
    "\n",
    "  #agent_module, agent_name = FLAGS.agent.rsplit(\".\", 1)\n",
    "  #agent_cls = getattr(importlib.import_module(agent_module), agent_name)\n",
    "  #agent_classes.append(agent_cls)\n",
    "  agent_classes.append(TerranRLAgentWithRawActsAndRawObs)\n",
    "  players.append(sc2_env.Agent(sc2_env.Race[FLAGS.agent_race]))\n",
    "\n",
    "  if map_inst.players >= 2:\n",
    "    if FLAGS.agent2 == \"Bot\":\n",
    "      players.append(sc2_env.Bot(sc2_env.Race[FLAGS.agent2_race],\n",
    "                                 sc2_env.Difficulty[FLAGS.difficulty]))\n",
    "    else:\n",
    "      #agent_module, agent_name = FLAGS.agent2.rsplit(\".\", 1)\n",
    "      #agent_cls = getattr(importlib.import_module(agent_module), agent_name)\n",
    "      agent_classes.append(TerranRandomAgent)\n",
    "      players.append(sc2_env.Agent(sc2_env.Race[FLAGS.agent2_race]))\n",
    "\n",
    "  threads = []\n",
    "  for _ in range(FLAGS.parallel - 1):\n",
    "    t = threading.Thread(target=run_thread,\n",
    "                         args=(agent_classes, players, FLAGS.map, False))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "  run_thread(agent_classes, players, FLAGS.map, FLAGS.render)\n",
    "\n",
    "  for t in threads:\n",
    "    t.join()\n",
    "\n",
    "  if FLAGS.profile:\n",
    "    pass\n",
    "    #print(stopwatch.sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a PySC2 Agent with Raw Actions & Observations\n",
    "\n",
    "![StarCraft2 PySC2 interfaces](./images/StarCraft2_PySC2_interfaces.png)\n",
    "\n",
    "ref : https://on-demand.gputechconf.com/gtc/2018/presentation/s8739-machine-learning-with-starcraft-II.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### < PySC2 Interfaces 3가지 종류 >\n",
    "\n",
    "### 1st, Rendered\n",
    "* Decomposed :\n",
    "    - Screen, minimap, resources, available actions\n",
    "* Same control as humans :\n",
    "    - Pixel coordinates\n",
    "    - Move camera\n",
    "    - Select unit/rectangle\n",
    "* Great for Deep Learning, but hard\n",
    "\n",
    "### 2nd, Feature Layer\n",
    "* Same actions : still in pixel space\n",
    "* Same decomposed observations, but more abstract\n",
    "    - Orthogonal camera \n",
    "* Layers:\n",
    "    - unit type\n",
    "    - unit owner\n",
    "    - selection\n",
    "    - health\n",
    "    - unit density\n",
    "    - etc\n",
    "    \n",
    "### 3rd, Raw\n",
    "* List of units and state\n",
    "* Control each unit individually in world coordinates\n",
    "* Gives all observable state (no camera)\n",
    "* Great for scripted agents and programmatic replay analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### < Raw Actions & Observations 을 사용하는 이유>\n",
    "* Raw Actions & Observations 은 world cordinates를 사용하므로 전체 Map을 한번에 관찰하고 Camera를 이동하지 않고도 Map 상의 어느 곳에서도 Action을 취할 수 있는 새로운 형태의 Feature 이다.\n",
    "* 이번 과정에 SL(Supervised Learning, 지도학습)을 활용한 학습은 없지만 스타크래프트 2 리플레이를 활용한 SL은 Raw Actions & Observations를 활용한 \"programmatic replay analysis\"가 필요하다.\n",
    "* 인간 플레이어를 이긴 DeepMind의 AlphaStar의 주요 변경사항 중의 하나는 Raw Actions & Observations 의 활용이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Applying Vanilla DQN to a PySC2 Agent\n",
    "\n",
    "구현된 기능\n",
    "\n",
    "- Implementing 'Experience Replay' : \n",
    "    - 'Maximization Bias' 문제를 발생시키는 원인 중 하나인 'Sample간의 시간적 연관성'을 해결하기 위한 방법\n",
    "    - Online Learning 에서 Batch Learning 으로 학습방법 바뀜 : Online update 는 Batch update 보다 일반적으로 Validation loss 가 더 높게 나타남.\n",
    "    - Reinforcement Learning for Robots. Using Neural Networks. Long -Ji Lin. January 6, 1993. 논문에서 최초로 연구됨 http://isl.anthropomatik.kit.edu/pdf/Lin1993.pdf\n",
    "\n",
    "- Implementing 'Fixed Q-Target' : \n",
    "    - 'Moving Q-Target' 문제 해결하기 위한 방법\n",
    "    - 2015년 Nature 버전 DQN 논문에서 처음 제안됨. https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning \n",
    "\n",
    "\n",
    "구현되지 않은 기능\n",
    "\n",
    "- Implementing 'Sensory Input Feature-Extraction' :\n",
    "    - 게임의 Raw Image 를 Neural Net에 넣기 위한 Preprocessing(전처리) 과정\n",
    "    - Raw Image 의 Sequence중 '최근 4개의 이미지'(과거 정보)를 하나의 새로운 State로 정의하여 non-MDP를 MDP 문제로 바꾸는 Preprocessing 과정 \n",
    "    - CNN(합성곱 신경망)을 활용한 '차원의 저주' 극복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import pickle\n",
    "\n",
    "from pysc2.agents import base_agent\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions, features, units\n",
    "from absl import app\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from skdrl.pytorch.model.mlp import NaiveMultiLayerPerceptron\n",
    "from skdrl.common.memory.memory import ExperienceReplayMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_QNET = 'rlagent_with_vanilla_dqn_qnet'\n",
    "DATA_FILE_QNET_TARGET = 'rlagent_with_vanilla_dqn_qnet_target'\n",
    "SCORE_FILE = 'rlagent_with_vanilla_dqn_score'\n",
    "\n",
    "scores = []                        # list containing scores from each episode\n",
    "scores_window = deque(maxlen=100)  # last 100 scores\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-update 공식\n",
    "\n",
    "#### 1. Online Q-learning\n",
    "![Online Q-learning](./images/q-update-experience-replay.png)\n",
    "\n",
    "#### 2. Online Q-learning with Function Approximation\n",
    "![Online Q-learning with Function Approximation](./images/q-update-function-approximation.png)\n",
    "\n",
    "#### 3. Batch Q-learning with Function Approximation & Experience Replay\n",
    "![Batch Q-learning with Function Approximation & Experience Replay](./images/q-update-online.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving target problem\n",
    "\n",
    "#### 1. Function Approximation을 사용하지 않는 Q-learning 의 경우 : 특정한 Q(s,a) update가 다른 Q(s,a)에 영향을 주지 않는다.\n",
    "![Moving target Q-learning](./images/moving-target_q-learing_case.png)\n",
    "\n",
    "#### 2. Function Approximation을 사용하는 Q-learnig 의 경우 : 특정한 Q(s,a) update가 다른 Q(s,a)에 영향을 준다.\n",
    "![Moving target Q-learning with Function Approximation](./images/moving-target_q-learing_with_function_approximation_case.png)\n",
    "\n",
    "### Moving target 문제는 Deep Neural Network를 사용하는 Function Approximation 기법인 경우 심해지는 경향성이 있음.\n",
    "\n",
    "image ref : Fast Campus RL online courese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `nn.SmoothL1Loss()` = Huber loss 란?\n",
    "\n",
    "Mean-squared Error (MSE) Loss 는 데이터의 outlier에 매우 취약하다.\n",
    "어떤 이유로 타겟하는 레이블 y (이 경우는 q-learning target)이 noisy 할때를 가정하면, 잘못된 y 값을 맞추기 위해 파라미터들이 너무 sensitive 하게 움직이게 된다.\n",
    "\n",
    "이런 현상은 q-learning 의 학습초기에 매우 빈번해 나타난다. 이러한 문제를 조금이라도 완화하기 위해서 outlier에 덜 민감한 Huber loss 함수를 사용한다.\n",
    "\n",
    "### SmoothL1Loss (aka Huber loss)\n",
    "\n",
    "$$loss(x,y) = \\frac{1}{n}\\sum_i z_i$$\n",
    "$|x_i - y_i| <1$ 일때,\n",
    "$$z_i = 0.5(x_i - y_i)^2$$\n",
    "$|x_i - y_i| \\geq1$ 일때,\n",
    "$$z_i = |x_i - y_i|-0.5$$\n",
    "\n",
    "ref : https://pytorch.org/docs/master/generated/torch.nn.SmoothL1Loss.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 state_dim: int,\n",
    "                 action_dim: int,\n",
    "                 qnet: nn.Module,\n",
    "                 qnet_target: nn.Module,\n",
    "                 lr: float,\n",
    "                 gamma: float,\n",
    "                 epsilon: float):\n",
    "        \"\"\"\n",
    "        :param state_dim: input state dimension\n",
    "        :param action_dim: action dimension\n",
    "        :param qnet: main q network\n",
    "        :param qnet_target: target q network\n",
    "        :param lr: learning rate\n",
    "        :param gamma: discount factor of MDP\n",
    "        :param epsilon: E-greedy factor\n",
    "        \"\"\"\n",
    "\n",
    "        super(DQN, self).__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.qnet = qnet\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.opt = torch.optim.Adam(params=self.qnet.parameters(), lr=lr)\n",
    "        self.register_buffer('epsilon', torch.ones(1) * epsilon)\n",
    "\n",
    "        # target network related\n",
    "        qnet_target.load_state_dict(qnet.state_dict())\n",
    "        self.qnet_target = qnet_target\n",
    "        self.criteria = nn.SmoothL1Loss()\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        qs = self.qnet(state)\n",
    "        #prob = np.random.uniform(0.0, 1.0, 1)\n",
    "        #if torch.from_numpy(prob).float() <= self.epsilon:  # random\n",
    "        if random.random() <= self.epsilon: # random\n",
    "            action = np.random.choice(range(self.action_dim))\n",
    "        else:  # greedy\n",
    "            action = qs.argmax(dim=-1)\n",
    "        return int(action)\n",
    "\n",
    "    def learn(self, state, action, reward, next_state, done):\n",
    "        s, a, r, ns = state, action, reward, next_state\n",
    "\n",
    "        # compute Q-Learning target with 'target network'\n",
    "        with torch.no_grad():\n",
    "            q_max, _ = self.qnet_target(ns).max(dim=-1, keepdims=True)\n",
    "            q_target = r + self.gamma * q_max * (1 - done)\n",
    "\n",
    "        q_val = self.qnet(s).gather(1, a)\n",
    "        loss = self.criteria(q_val, q_target)\n",
    "\n",
    "        self.opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "\n",
    "\n",
    "def prepare_training_inputs(sampled_exps, device='cpu'):\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    next_states = []\n",
    "    dones = []\n",
    "    for sampled_exp in sampled_exps:\n",
    "        states.append(sampled_exp[0])\n",
    "        actions.append(sampled_exp[1])\n",
    "        rewards.append(sampled_exp[2])\n",
    "        next_states.append(sampled_exp[3])\n",
    "        dones.append(sampled_exp[4])\n",
    "\n",
    "    states = torch.cat(states, dim=0).float().to(device)\n",
    "    actions = torch.cat(actions, dim=0).to(device)\n",
    "    rewards = torch.cat(rewards, dim=0).float().to(device)\n",
    "    next_states = torch.cat(next_states, dim=0).float().to(device)\n",
    "    dones = torch.cat(dones, dim=0).float().to(device)\n",
    "    return states, actions, rewards, next_states, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerranAgentWithRawActsAndRawObs(base_agent.BaseAgent):\n",
    "    actions = (\"do_nothing\",\n",
    "               \n",
    "               \"harvest_vespene\",\n",
    "               \"build_refinery\",\n",
    "               \"build_supply_depot\",\n",
    "               \"build_supply_depot_2\",\n",
    "               \"build_supply_possible_spot\",\n",
    "               \"build_barracks\",\n",
    "               \"build_factory_techlab\",\n",
    "               \"build_factory\",\n",
    "               \"train_marine\",\n",
    "               \"train_tank\",\n",
    "               \"attack\",\n",
    "               \"attack_multi\",\n",
    "               \"attack_with_random_unit\"\n",
    "              ) #harvest_mineral deleted\n",
    "\n",
    "    def get_my_units_by_type(self, obs, unit_type):\n",
    "        return [unit for unit in obs.observation.raw_units\n",
    "                if unit.unit_type == unit_type\n",
    "                and unit.alliance == features.PlayerRelative.SELF]\n",
    "\n",
    "    def get_enemy_units_by_type(self, obs, unit_type):\n",
    "        return [unit for unit in obs.observation.raw_units\n",
    "                if unit.unit_type == unit_type\n",
    "                and unit.alliance == features.PlayerRelative.ENEMY]\n",
    "\n",
    "    def get_my_completed_units_by_type(self, obs, unit_type):\n",
    "        return [unit for unit in obs.observation.raw_units\n",
    "                if unit.unit_type == unit_type\n",
    "                and unit.build_progress == 100\n",
    "                and unit.alliance == features.PlayerRelative.SELF]\n",
    "\n",
    "    def get_enemy_completed_units_by_type(self, obs, unit_type):\n",
    "        return [unit for unit in obs.observation.raw_units\n",
    "                if unit.unit_type == unit_type\n",
    "                and unit.build_progress == 100\n",
    "                and unit.alliance == features.PlayerRelative.ENEMY]\n",
    "\n",
    "    def get_distances(self, obs, units, xy):\n",
    "        units_xy = [(unit.x, unit.y) for unit in units]\n",
    "        return np.linalg.norm(np.array(units_xy) - np.array(xy), axis=1)\n",
    "\n",
    "    def step(self, obs):\n",
    "        super(TerranAgentWithRawActsAndRawObs, self).step(obs)\n",
    "        if obs.first():\n",
    "            command_center = self.get_my_units_by_type(\n",
    "                obs, units.Terran.CommandCenter)[0]\n",
    "            self.base_top_left = (command_center.x < 32)\n",
    "\n",
    "    def do_nothing(self, obs):\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "\n",
    "    def harvest_minerals(self, obs):\n",
    "        scvs = self.get_my_units_by_type(obs, units.Terran.SCV)\n",
    "        idle_scvs = [scv for scv in scvs if scv.order_length == 0]\n",
    "        if len(idle_scvs) > 0:\n",
    "            mineral_patches = [unit for unit in obs.observation.raw_units\n",
    "                               if unit.unit_type in [\n",
    "                                   units.Neutral.BattleStationMineralField,\n",
    "                                   units.Neutral.BattleStationMineralField750,\n",
    "                                   units.Neutral.LabMineralField,\n",
    "                                   units.Neutral.LabMineralField750,\n",
    "                                   units.Neutral.MineralField,\n",
    "                                   units.Neutral.MineralField750,\n",
    "                                   units.Neutral.PurifierMineralField,\n",
    "                                   units.Neutral.PurifierMineralField750,\n",
    "                                   units.Neutral.PurifierRichMineralField,\n",
    "                                   units.Neutral.PurifierRichMineralField750,\n",
    "                                   units.Neutral.RichMineralField,\n",
    "                                   units.Neutral.RichMineralField750\n",
    "                               ]]\n",
    "            scv = random.choice(idle_scvs)\n",
    "            distances = self.get_distances(obs, mineral_patches, (scv.x, scv.y))\n",
    "            mineral_patch = mineral_patches[np.argmin(distances)]\n",
    "            return actions.RAW_FUNCTIONS.Harvest_Gather_unit(\n",
    "                \"now\", scv.tag, mineral_patch.tag)\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "    \n",
    "    def harvest_vespene(self, obs):\n",
    "        completed_refinery = self.get_my_completed_units_by_type(obs, units.Terran.Refinery)\n",
    "        scvs = self.get_my_units_by_type(obs, units.Terran.SCV)\n",
    "        idle_scvs = [scv for scv in scvs if scv.order_length == 0]\n",
    "        if len(idle_scvs) > 0 and len(completed_refinery) > 0:\n",
    "            completed_refinery = self.get_my_completed_units_by_type(obs, units.Terran.Refinery)\n",
    "            scv = random.choice(idle_scvs)\n",
    "            distances = self.get_distances(obs, completed_refinery, (scv.x, scv.y))\n",
    "            refinery = completed_refinery[np.argmin(distances)]\n",
    "            return actions.RAW_FUNCTIONS.Harvest_Gather_unit(\n",
    "                \"now\", scv.tag, refinery.tag)\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "\n",
    "    def build_refinery(self, obs):\n",
    "        vespene = [unit for unit in obs.observation.raw_units if unit.unit_type == units.Neutral.VespeneGeyser]\n",
    "        refineries = self.get_my_units_by_type(obs, units.Terran.Refinery)\n",
    "        scvs = self.get_my_units_by_type(obs, units.Terran.SCV)\n",
    "        if len(scvs) == 0:\n",
    "            return actions.RAW_FUNCTIONS.no_op()\n",
    "        scv = random.choice(scvs)\n",
    "        distances = self.get_distances(obs, vespene, (scv.x, scv.y))\n",
    "        vespene_patch = vespene[np.argmin(distances)]\n",
    "        if (obs.observation.player.minerals >= 100 and len(scvs) > 0 and len(vespene) > 0 and len(refineries) < 3):\n",
    "            return actions.RAW_FUNCTIONS.Build_Refinery_pt(\"now\", scvs[0].tag, vespene_patch.tag)\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "    \n",
    "    def build_supply_depot(self, obs):\n",
    "        supply_depots = self.get_my_units_by_type(obs, units.Terran.SupplyDepot)\n",
    "        scvs = self.get_my_units_by_type(obs, units.Terran.SCV)\n",
    "        if (len(supply_depots) == 0 and obs.observation.player.minerals >= 100 and\n",
    "                len(scvs) > 0 ):\n",
    "            supply_depot_xy = (22, 26) if self.base_top_left else (35, 42)\n",
    "            distances = self.get_distances(obs, scvs, supply_depot_xy)\n",
    "            scv = scvs[np.argmin(distances)]\n",
    "            return actions.RAW_FUNCTIONS.Build_SupplyDepot_pt(\n",
    "                \"now\", scv.tag, supply_depot_xy)\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "    \n",
    "    def build_supply_depot_2(self, obs):\n",
    "        supply_depots = self.get_my_units_by_type(obs, units.Terran.SupplyDepot)\n",
    "        scvs = self.get_my_units_by_type(obs, units.Terran.SCV)\n",
    "        if (len(supply_depots) == 1 and obs.observation.player.minerals >= 100 and\n",
    "                len(scvs) > 0):\n",
    "            supply_depot_xy = (24, 26) if self.base_top_left else (35, 40)\n",
    "            distances = self.get_distances(obs, scvs, supply_depot_xy)\n",
    "            scv = scvs[np.argmin(distances)]\n",
    "            return actions.RAW_FUNCTIONS.Build_SupplyDepot_pt(\n",
    "                \"now\", scv.tag, supply_depot_xy)\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "    \n",
    "    def build_supply_possible_spot(self, obs):\n",
    "        supply_depots = self.get_my_units_by_type(obs, units.Terran.SupplyDepot)\n",
    "        scvs = self.get_my_units_by_type(obs, units.Terran.SCV)\n",
    "        free_supply = (obs.observation.player.food_cap - obs.observation.player.food_used)\n",
    "        if (len(supply_depots) >= 2 and obs.observation.player.minerals >= 100 and len(scvs) > 0 and free_supply < 5):\n",
    "            myspot_xy = [38, 23] if self.base_top_left else [19, 44]\n",
    "            x_offset = random.randint(-4, 4)\n",
    "            y_offset = random.randint(-4, 4)\n",
    "            myspot_xy = (myspot_xy[0] + x_offset, myspot_xy[1] + y_offset)\n",
    "            distances = self.get_distances(obs, scvs, myspot_xy)\n",
    "            scv = scvs[np.argmin(distances)]\n",
    "            return actions.RAW_FUNCTIONS.Build_SupplyDepot_pt(\"now\", scv.tag, myspot_xy)\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "            \n",
    "\n",
    "    def build_barracks(self, obs):\n",
    "        completed_supply_depots = self.get_my_completed_units_by_type(\n",
    "            obs, units.Terran.SupplyDepot)\n",
    "        barrackses = self.get_my_units_by_type(obs, units.Terran.Barracks)\n",
    "        scvs = self.get_my_units_by_type(obs, units.Terran.SCV)\n",
    "        if (len(completed_supply_depots) > 0 and len(barrackses) == 0 and\n",
    "                obs.observation.player.minerals >= 150 and len(scvs) > 0):\n",
    "            barracks_xy = (22, 21) if self.base_top_left else (35, 45)\n",
    "            distances = self.get_distances(obs, scvs, barracks_xy)\n",
    "            scv = scvs[np.argmin(distances)]\n",
    "            return actions.RAW_FUNCTIONS.Build_Barracks_pt(\n",
    "                \"now\", scv.tag, barracks_xy)\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "\n",
    "    def build_factory(self, obs):\n",
    "        completed_barrackes = self.get_my_completed_units_by_type(obs, units.Terran.Barracks)\n",
    "        factories = self.get_my_units_by_type(obs, units.Terran.Factory)\n",
    "        scvs = self.get_my_units_by_type(obs, units.Terran.SCV)\n",
    "        if (len(completed_barrackes) > 0 and len(factories) == 0 and\n",
    "                obs.observation.player.minerals >= 150 and obs.observation.player.vespene >= 100 and len(scvs) > 0):\n",
    "            factory_xy = (23, 23) if self.base_top_left else (38, 40)\n",
    "            distances = self.get_distances(obs, scvs, factory_xy)\n",
    "            scv = scvs[np.argmin(distances)]\n",
    "            return actions.RAW_FUNCTIONS.Build_Factory_pt(\n",
    "                \"now\", scv.tag, factory_xy)\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "    \n",
    "    def build_factory_techlab(self, obs):\n",
    "        completed_factory = self.get_my_completed_units_by_type(obs, units.Terran.Factory)\n",
    "        if len(completed_factory) > 0 and obs.observation.player.minerals >= 50 and obs.observation.player.vespene >= 25:\n",
    "            factory = random.choice(completed_factory)\n",
    "            return actions.RAW_FUNCTIONS.Build_TechLab_Factory_quick(\"now\", factory.tag)\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "\n",
    "    def train_marine(self, obs):\n",
    "        completed_barrackses = self.get_my_completed_units_by_type(\n",
    "            obs, units.Terran.Barracks)\n",
    "        free_supply = (obs.observation.player.food_cap -\n",
    "                       obs.observation.player.food_used)\n",
    "        if (len(completed_barrackses) > 0 and obs.observation.player.minerals >= 100\n",
    "                and free_supply > 0):\n",
    "            barracks = self.get_my_units_by_type(obs, units.Terran.Barracks)[0]\n",
    "            if barracks.order_length < 5:\n",
    "                return actions.RAW_FUNCTIONS.Train_Marine_quick(\"now\", barracks.tag)\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "    \n",
    "    def train_tank(self, obs):\n",
    "        completed_factory = self.get_my_completed_units_by_type(obs, units.Terran.Factory)\n",
    "        completed_factory_techlab = self.get_my_completed_units_by_type(obs, units.Terran.FactoryTechLab)\n",
    "        free_supply = (obs.observation.player.food_cap - obs.observation.player.food_used)\n",
    "        if (len(completed_factory) > 0 and len(completed_factory_techlab) > 0\n",
    "            and obs.observation.player.minerals >= 150 and obs.observation.player.vespene >= 125\n",
    "            and free_supply >= 3):\n",
    "            factory = self.get_my_units_by_type(obs, units.Terran.Factory)[0]\n",
    "            if factory.order_length < 5:\n",
    "                return actions.RAW_FUNCTIONS.Train_SiegeTank_quick(\"now\", factory.tag)\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "\n",
    "    def attack(self, obs):\n",
    "        marines = self.get_my_units_by_type(obs, units.Terran.Marine)\n",
    "        tanks = self.get_my_units_by_type(obs, units.Terran.SiegeTank)\n",
    "        attack_units = marines + tanks\n",
    "        if len(attack_units) > 0:\n",
    "            attack_xy = (38, 44) if self.base_top_left else (19, 23)\n",
    "            distances = self.get_distances(obs, attack_units, attack_xy)\n",
    "            attack_unit = attack_units[np.argmax(distances)]\n",
    "            x_offset = random.randint(-4, 4)\n",
    "            y_offset = random.randint(-4, 4)\n",
    "            return actions.RAW_FUNCTIONS.Attack_pt(\n",
    "                \"now\", attack_unit.tag, (attack_xy[0] + x_offset, attack_xy[1] + y_offset))\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "    \n",
    "    def attack_multi(self, obs):\n",
    "        marines = self.get_my_units_by_type(obs, units.Terran.Marine)\n",
    "        tanks = self.get_my_units_by_type(obs, units.Terran.SiegeTank)\n",
    "        attack_units = marines + tanks\n",
    "        if len(attack_units) > 0:\n",
    "            attack_xy = (19, 44) if self.base_top_left else (38, 23)\n",
    "            distances = self.get_distances(obs, attack_units, attack_xy)\n",
    "            attack_unit = attack_units[np.argmax(distances)]\n",
    "            x_offset = random.randint(-4, 4)\n",
    "            y_offset = random.randint(-4, 4)\n",
    "            return actions.RAW_FUNCTIONS.Attack_pt(\n",
    "                \"now\", attack_unit.tag, (attack_xy[0] + x_offset, attack_xy[1] + y_offset))\n",
    "        return actions.RAW_FUNCTIONS.no_op()\n",
    "    \n",
    "    def attack_with_random_unit(self, obs):\n",
    "        marines = self.get_my_units_by_type(obs, units.Terran.Marine)\n",
    "        tanks = self.get_my_units_by_type(obs, units.Terran.SiegeTank)\n",
    "        attack_units = marines + tanks\n",
    "        if len(attack_units) > 0:\n",
    "            attack_xy = (38, 44) if self.base_top_left else (19, 23)\n",
    "            attack_unit = random.choice(attack_units)\n",
    "            x_offset = random.randint(-4, 4)\n",
    "            y_offset = random.randint(-4, 4)\n",
    "            return actions.RAW_FUNCTIONS.Attack_pt(\n",
    "                \"now\", attack_unit.tag, (attack_xy[0] + x_offset, attack_xy[1] + y_offset))\n",
    "        return actions.RAW_FUNCTIONS.no_op()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerranRandomAgent(TerranAgentWithRawActsAndRawObs):\n",
    "    def step(self, obs):\n",
    "        super(TerranRandomAgent, self).step(obs)\n",
    "        action = random.choice(self.actions)\n",
    "        return getattr(self, action)(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter\n",
    "\n",
    "하이퍼파라미터는 심층강화학습 알고리즘에서 성능에 매우 큰 영향을 미칩니다.\n",
    "이 실험에 쓰인 하이퍼파라미터는 https://github.com/chucnorrisful/dqn 실험에서 제안된 값들을 참고하였습니다.\n",
    "\n",
    "\n",
    "- self.s_dim = 21\n",
    "- self.a_dim = 6\n",
    "\n",
    "- self.lr = 1e-4 * 1\n",
    "- self.batch_size = 32\n",
    "- self.gamma = 0.99\n",
    "- self.memory_size = 200000\n",
    "- self.eps_max = 1.0\n",
    "- self.eps_min = 0.01\n",
    "- self.epsilon = 1.0\n",
    "- self.init_sampling = 4000\n",
    "- self.target_update_interval = 10\n",
    "\n",
    "- self.epsilon = max(self.eps_min, self.eps_max - self.eps_min * (self.episode_count / 50))\n",
    "\n",
    "\n",
    "![Winning rate graph](./images/rlagent_with_vanilla_dqn_score-Terran-Terran-495_Eps.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerranRLAgentWithRawActsAndRawObs(TerranAgentWithRawActsAndRawObs):\n",
    "    def __init__(self):\n",
    "        super(TerranRLAgentWithRawActsAndRawObs, self).__init__()\n",
    "\n",
    "        self.s_dim = 25\n",
    "        self.a_dim = 14\n",
    "        \n",
    "        self.lr = 1e-4 * 1\n",
    "        self.batch_size = 32\n",
    "        self.gamma = 0.99\n",
    "        self.memory_size = 200000\n",
    "        self.eps_max = 1.0\n",
    "        self.eps_min = 0.01\n",
    "        self.epsilon = 1.0\n",
    "        self.init_sampling = 4000\n",
    "        self.target_update_interval = 10\n",
    "\n",
    "        self.data_file_qnet = DATA_FILE_QNET\n",
    "        self.data_file_qnet_target = DATA_FILE_QNET_TARGET\n",
    "        self.score_file = SCORE_FILE\n",
    "        \n",
    "        self.qnetwork = NaiveMultiLayerPerceptron(input_dim=self.s_dim,\n",
    "                           output_dim=self.a_dim,\n",
    "                           num_neurons=[128],\n",
    "                           hidden_act_func='ReLU',\n",
    "                           out_act_func='Identity').to(device)\n",
    "        \n",
    "        self.qnetwork_target = NaiveMultiLayerPerceptron(input_dim=self.s_dim,\n",
    "                           output_dim=self.a_dim,\n",
    "                           num_neurons=[128],\n",
    "                           hidden_act_func='ReLU',\n",
    "                           out_act_func='Identity').to(device)\n",
    "        \n",
    "        if os.path.isfile(self.data_file_qnet + '.pt'):\n",
    "            self.qnetwork.load_state_dict(torch.load(self.data_file_qnet + '.pt'))\n",
    "            \n",
    "        if os.path.isfile(self.data_file_qnet_target + '.pt'):\n",
    "            self.qnetwork_target.load_state_dict(torch.load(self.data_file_qnet_target + '.pt'))\n",
    "        \n",
    "        # initialize target network same as the main network.\n",
    "        self.qnetwork_target.load_state_dict(self.qnetwork.state_dict())\n",
    "\n",
    "        self.dqn = DQN(state_dim=self.s_dim,\n",
    "                             action_dim=self.a_dim,\n",
    "                             qnet=self.qnetwork,\n",
    "                             qnet_target=self.qnetwork_target,\n",
    "                             lr=self.lr,\n",
    "                             gamma=self.gamma,\n",
    "                             epsilon=self.epsilon).to(device)\n",
    "        \n",
    "        self.memory = ExperienceReplayMemory(self.memory_size)\n",
    "        \n",
    "        self.print_every = 1\n",
    "        self.cum_reward = 0\n",
    "        self.cum_loss = 0\n",
    "        self.episode_count = 0\n",
    "        \n",
    "        self.new_game()\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        super(TerranRLAgentWithRawActsAndRawObs, self).reset()\n",
    "        self.new_game()\n",
    "\n",
    "    def new_game(self):\n",
    "        self.base_top_left = None\n",
    "        self.previous_state = None\n",
    "        self.previous_action = None\n",
    "        self.cum_reward = 0\n",
    "        self.cum_loss = 0\n",
    "        \n",
    "        # epsilon scheduling\n",
    "        # slowly decaying_epsilon\n",
    "        self.epsilon = max(self.eps_min, self.eps_max - self.eps_min * (self.episode_count / 50))\n",
    "        self.dqn.epsilon = torch.tensor(self.epsilon).to(device)\n",
    "        \n",
    "\n",
    "    def get_state(self, obs):\n",
    "        scvs = self.get_my_units_by_type(obs, units.Terran.SCV)\n",
    "        idle_scvs = [scv for scv in scvs if scv.order_length == 0]\n",
    "        command_centers = self.get_my_units_by_type(obs, units.Terran.CommandCenter)\n",
    "        supply_depots = self.get_my_units_by_type(obs, units.Terran.SupplyDepot)\n",
    "        completed_supply_depots = self.get_my_completed_units_by_type(\n",
    "            obs, units.Terran.SupplyDepot)\n",
    "        barrackses = self.get_my_units_by_type(obs, units.Terran.Barracks)\n",
    "        completed_barrackses = self.get_my_completed_units_by_type(obs, units.Terran.Barracks)\n",
    "        completed_factory = self.get_my_completed_units_by_type(obs, units.Terran.Factory) # added\n",
    "        marines = self.get_my_units_by_type(obs, units.Terran.Marine)\n",
    "        tanks = self.get_my_units_by_type(obs, units.Terran.SiegeTank) # added\n",
    "\n",
    "        queued_marines = (completed_barrackses[0].order_length if len(completed_barrackses) > 0 else 0)\n",
    "        queued_tanks = (completed_factory[0].order_length if len(completed_factory) > 0 else 0)\n",
    "\n",
    "        free_supply = (obs.observation.player.food_cap - obs.observation.player.food_used)\n",
    "        can_afford_supply_depot = obs.observation.player.minerals >= 100\n",
    "        can_afford_barracks = obs.observation.player.minerals >= 150\n",
    "        can_afford_marine = obs.observation.player.minerals >= 100\n",
    "        \n",
    "        can_afford_factory = (obs.observation.player.minerals >= 150 and obs.observation.player.vespene >= 100) # added\n",
    "        can_afford_tank = (obs.observation.player.minerals >= 150 and obs.observation.player.vespene >= 125) # added\n",
    "\n",
    "        enemy_scvs = self.get_enemy_units_by_type(obs, units.Terran.SCV)\n",
    "        enemy_idle_scvs = [scv for scv in enemy_scvs if scv.order_length == 0]\n",
    "        enemy_command_centers = self.get_enemy_units_by_type(\n",
    "            obs, units.Terran.CommandCenter)\n",
    "        enemy_supply_depots = self.get_enemy_units_by_type(\n",
    "            obs, units.Terran.SupplyDepot)\n",
    "        enemy_completed_supply_depots = self.get_enemy_completed_units_by_type(\n",
    "            obs, units.Terran.SupplyDepot)\n",
    "        enemy_barrackses = self.get_enemy_units_by_type(obs, units.Terran.Barracks)\n",
    "        enemy_completed_barrackses = self.get_enemy_completed_units_by_type(\n",
    "            obs, units.Terran.Barracks)\n",
    "        enemy_marines = self.get_enemy_units_by_type(obs, units.Terran.Marine)\n",
    "\n",
    "        return (len(command_centers),\n",
    "                len(scvs),\n",
    "                len(idle_scvs),\n",
    "                len(supply_depots),\n",
    "                len(completed_supply_depots),\n",
    "                len(barrackses),\n",
    "                len(completed_barrackses),\n",
    "                len(marines),\n",
    "                queued_marines,\n",
    "                free_supply,\n",
    "                can_afford_supply_depot,\n",
    "                can_afford_barracks,\n",
    "                can_afford_marine,\n",
    "                \n",
    "                len(completed_factory),\n",
    "                len(tanks),\n",
    "                can_afford_factory,\n",
    "                can_afford_tank,\n",
    "                \n",
    "                \n",
    "                len(enemy_command_centers),\n",
    "                len(enemy_scvs),\n",
    "                len(enemy_idle_scvs),\n",
    "                len(enemy_supply_depots),\n",
    "                len(enemy_completed_supply_depots),\n",
    "                len(enemy_barrackses),\n",
    "                len(enemy_completed_barrackses),\n",
    "                len(enemy_marines))\n",
    "\n",
    "    def step(self, obs):\n",
    "        super(TerranRLAgentWithRawActsAndRawObs, self).step(obs)\n",
    "        \n",
    "        #time.sleep(0.5)\n",
    "        \n",
    "        state = self.get_state(obs)\n",
    "        state = torch.tensor(state).float().view(1, self.s_dim).to(device)\n",
    "        action_idx = self.dqn.choose_action(state)\n",
    "        action = self.actions[action_idx]\n",
    "        done = True if obs.last() else False\n",
    "\n",
    "        if self.previous_action is not None:\n",
    "            experience = (self.previous_state.to(device),\n",
    "                          torch.tensor(self.previous_action).view(1, 1).to(device),\n",
    "                          torch.tensor(obs.reward).view(1, 1).to(device),\n",
    "                          state.to(device),\n",
    "                          torch.tensor(done).view(1, 1).to(device))\n",
    "            self.memory.push(experience)\n",
    "        \n",
    "        self.cum_reward += obs.reward\n",
    "        self.previous_state = state\n",
    "        self.previous_action = action_idx\n",
    "        \n",
    "        if obs.last():\n",
    "            self.episode_count = self.episode_count + 1\n",
    "            \n",
    "            if len(self.memory) >= self.init_sampling:\n",
    "                # training dqn\n",
    "                sampled_exps = self.memory.sample(self.batch_size)\n",
    "                sampled_exps = prepare_training_inputs(sampled_exps, device)\n",
    "                self.dqn.learn(*sampled_exps)\n",
    "\n",
    "            if self.episode_count % self.target_update_interval == 0:\n",
    "                self.dqn.qnet_target.load_state_dict(self.dqn.qnet.state_dict())\n",
    "\n",
    "            if self.episode_count % self.print_every == 0:\n",
    "                msg = (self.episode_count, self.cum_reward, self.epsilon)\n",
    "                print(\"Episode : {:4.0f} | Cumulative Reward : {:4.0f} | Epsilon : {:.3f}\".format(*msg))\n",
    "            \n",
    "            torch.save(self.dqn.qnet.state_dict(), self.data_file_qnet + '.pt')\n",
    "            torch.save(self.dqn.qnet_target.state_dict(), self.data_file_qnet_target + '.pt')\n",
    "\n",
    "            scores_window.append(obs.reward)  # save most recent reward\n",
    "            win_rate = scores_window.count(1)/len(scores_window)*100\n",
    "            tie_rate = scores_window.count(0)/len(scores_window)*100\n",
    "            lost_rate = scores_window.count(-1)/len(scores_window)*100\n",
    "            \n",
    "            scores.append([win_rate, tie_rate, lost_rate])  # save most recent score(win_rate, tie_rate, lost_rate)\n",
    "            with open(self.score_file + '.txt', \"wb\") as fp:\n",
    "                pickle.dump(scores, fp)\n",
    "            \n",
    "            #writer.add_scalar(\"Loss/train\", self.cum_loss/obs.observation.game_loop, self.episode_count)\n",
    "            writer.add_scalar(\"Score\", self.cum_reward, self.episode_count)\n",
    "\n",
    "        return getattr(self, action)(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0922 19:53:52.187998 21156 sc_process.py:135] Launching SC2: D:/InstallGames/Blizzard/StarCraft II\\Versions/Base81102\\SC2_x64.exe -listen 127.0.0.1 -port 19532 -dataDir D:/InstallGames/Blizzard/StarCraft II\\ -tempDir C:\\Users\\ruzun\\AppData\\Local\\Temp\\sc-_oizd5zs\\ -displayMode 0 -windowwidth 640 -windowheight 480 -windowx 50 -windowy 50\n",
      "I0922 19:53:52.532077 21156 remote_controller.py:167] Connecting to: ws://127.0.0.1:19532/sc2api, attempt: 0, running: True\n",
      "I0922 19:53:55.536040 21156 remote_controller.py:167] Connecting to: ws://127.0.0.1:19532/sc2api, attempt: 1, running: True\n",
      "I0922 19:53:58.540002 21156 remote_controller.py:167] Connecting to: ws://127.0.0.1:19532/sc2api, attempt: 2, running: True\n",
      "I0922 19:54:01.543963 21156 remote_controller.py:167] Connecting to: ws://127.0.0.1:19532/sc2api, attempt: 3, running: True\n",
      "I0922 19:54:10.448866 21156 sc2_env.py:314] Environment is ready\n",
      "I0922 19:54:10.465822 21156 sc2_env.py:507] Starting episode 1: [terran, terran] on Simple64\n",
      "I0922 19:55:04.071773 21156 sc2_env.py:725] Episode 1 finished after 10552 game steps. Outcome: [1], reward: [1], score: [5191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode :    1 | Cumulative Reward :    1 | Epsilon : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0922 19:55:07.916801 21156 sc2_env.py:507] Starting episode 2: [terran, terran] on Simple64\n",
      "I0922 19:55:09.907813 21156 sc2_env.py:752] Environment Close\n",
      "I0922 19:55:10.010536 21156 sc_process.py:232] Shutdown gracefully.\n",
      "I0922 19:55:10.011534 21156 sc_process.py:210] Shutdown with return code: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 59.442 seconds for 1372 steps: 23.081 fps\n"
     ]
    },
    {
     "ename": "WebSocketProtocolException",
     "evalue": "Illegal frame",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebSocketProtocolException\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-60174cc17dd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\absl\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv, flags_parser)\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m       \u001b[0m_run_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m       \u001b[0musage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\absl\\app.py\u001b[0m in \u001b[0;36m_run_main\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-6aa67a71997e>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(unused_argv)\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m   \u001b[0mrun_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-6aa67a71997e>\u001b[0m in \u001b[0;36mrun_thread\u001b[1;34m(agent_classes, players, map_name, visualize)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0mrun_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_agent_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_episodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_replay\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m       \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_replay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munused_argv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\env\\sc2_env.py\u001b[0m in \u001b[0;36msave_replay\u001b[1;34m(self, replay_dir, prefix)\u001b[0m\n\u001b[0;32m    745\u001b[0m       \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     replay_path = self._run_config.save_replay(\n\u001b[1;32m--> 747\u001b[1;33m         self._controllers[0].save_replay(), replay_dir, prefix)\n\u001b[0m\u001b[0;32m    748\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrote replay to: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplay_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreplay_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\remote_controller.py\u001b[0m in \u001b[0;36m_valid_status\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \"`%s` called while in state: %s, valid: (%s)\" % (\n\u001b[0;32m     98\u001b[0m                 func.__name__, self.status, \",\".join(map(str, valid))))\n\u001b[1;32m---> 99\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_valid_status\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\stopwatch.py\u001b[0m in \u001b[0;36m_stopwatch\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0m_stopwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_stopwatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\remote_controller.py\u001b[0m in \u001b[0;36msave_replay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_replay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;34m\"\"\"Save a replay, returning the data.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_replay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msc_pb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequestSaveReplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m       \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_req\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error during %s: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36msend_req\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;34m\"\"\"Write a pre-filled Request and return the Response.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\stopwatch.py\u001b[0m in \u001b[0;36m_stopwatch\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0m_stopwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_stopwatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 self._port)\n\u001b[0;32m    101\u001b[0m       \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc2_verbose_protocol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m       self._log(\"-------------- [%s] Read %s in %0.1f msec --------------\\n%s\",\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"read_response\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mcatch_websocket_connection_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mresponse_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresponse_str\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mProtocolError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Got an empty response from SC2.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_core.py\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \"\"\"\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mopcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mopcode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_TEXT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_core.py\u001b[0m in \u001b[0;36mrecv_data\u001b[1;34m(self, control_frame)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mreturn\u001b[0m  \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[0mopcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_data_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mopcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_core.py\u001b[0m in \u001b[0;36mrecv_data_frame\u001b[1;34m(self, control_frame)\u001b[0m\n\u001b[0;32m    349\u001b[0m                     \"Not a valid frame %s\" % frame)\n\u001b[0;32m    350\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopcode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_TEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_BINARY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_CONT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcont_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcont_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_abnf.py\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecving_frames\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopcode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_CONT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mWebSocketProtocolException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Illegal frame\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecving_frames\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m                 \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopcode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_TEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_BINARY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebSocketProtocolException\u001b[0m: Illegal frame"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Winning rate graph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "SCORE_FILE = 'rlagent_with_vanilla_dqn_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SCORE_FILE + '.txt', \"rb\") as fp:\n",
    "    scores = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_scores = np.array(scores)\n",
    "np_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(np_scores)), np_scores.T[0], color='r', label='win rate')\n",
    "plt.plot(np.arange(len(np_scores)), np_scores.T[1], color='g', label='tie rate')\n",
    "plt.plot(np.arange(len(np_scores)), np_scores.T[2], color='b', label='lose rate')\n",
    "plt.ylabel('Score %')\n",
    "plt.xlabel('Episode #')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starcraft2",
   "language": "python",
   "name": "starcraft2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
