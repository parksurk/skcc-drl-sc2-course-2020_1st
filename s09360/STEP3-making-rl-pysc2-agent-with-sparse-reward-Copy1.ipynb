{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 - Making RL PySC2 Agent with sparse reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Runnning 'Agent code' on jupyter notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# unfortunately, PySC2 uses Abseil, which treats python code as if its run like an app\n",
    "# This does not play well with jupyter notebook\n",
    "# So we will need to monkeypatch sys.argv\n",
    "\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS-IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"Run an agent.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import sys\n",
    "#sys.argv = [\"python\", \"--map\", \"AbyssalReef\"]\n",
    "sys.argv = [\"python\", \"--map\", \"Simple64\"]\n",
    "\n",
    "import importlib\n",
    "import threading\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from future.builtins import range  # pylint: disable=redefined-builtin\n",
    "\n",
    "from pysc2 import maps\n",
    "from pysc2.env import available_actions_printer\n",
    "from pysc2.env import run_loop\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import point_flag\n",
    "from pysc2.lib import stopwatch\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# because of Abseil's horrible design for running code underneath Colabs\n",
    "# We have to pull out this ugly hack from the hat\n",
    "if \"flags_defined\" not in globals():\n",
    "    flags.DEFINE_bool(\"render\", False, \"Whether to render with pygame.\")\n",
    "    point_flag.DEFINE_point(\"feature_screen_size\", \"84\",\n",
    "                            \"Resolution for screen feature layers.\")\n",
    "    point_flag.DEFINE_point(\"feature_minimap_size\", \"64\",\n",
    "                            \"Resolution for minimap feature layers.\")\n",
    "    point_flag.DEFINE_point(\"rgb_screen_size\", None,\n",
    "                            \"Resolution for rendered screen.\")\n",
    "    point_flag.DEFINE_point(\"rgb_minimap_size\", None,\n",
    "                            \"Resolution for rendered minimap.\")\n",
    "    flags.DEFINE_enum(\"action_space\", None, sc2_env.ActionSpace._member_names_,  # pylint: disable=protected-access\n",
    "                      \"Which action space to use. Needed if you take both feature \"\n",
    "                      \"and rgb observations.\")\n",
    "    flags.DEFINE_bool(\"use_feature_units\", True,\n",
    "                      \"Whether to include feature units.\")\n",
    "    flags.DEFINE_bool(\"disable_fog\", False, \"Whether to disable Fog of War.\")\n",
    "\n",
    "    flags.DEFINE_integer(\"max_agent_steps\", 0, \"Total agent steps.\")\n",
    "    flags.DEFINE_integer(\"game_steps_per_episode\", None, \"Game steps per episode.\")\n",
    "    flags.DEFINE_integer(\"max_episodes\", 0, \"Total episodes.\")\n",
    "    flags.DEFINE_integer(\"step_mul\", 8, \"Game steps per agent step.\")\n",
    "    flags.DEFINE_float(\"fps\", 22.4, \"Frames per second to run the game.\")\n",
    "\n",
    "    #flags.DEFINE_string(\"agent\", \"sc2.agent.BasicAgent.ZergBasicAgent\",\n",
    "    #                    \"Which agent to run, as a python path to an Agent class.\")\n",
    "    #flags.DEFINE_enum(\"agent_race\", \"zerg\", sc2_env.Race._member_names_,  # pylint: disable=protected-access\n",
    "    #                  \"Agent 1's race.\")\n",
    "    flags.DEFINE_string(\"agent\", \"TerranSparseRewardRLAgent\",\n",
    "                        \"Which agent to run, as a python path to an Agent class.\")\n",
    "    flags.DEFINE_enum(\"agent_race\", \"terran\", sc2_env.Race._member_names_,  # pylint: disable=protected-access\n",
    "                      \"Agent 1's race.\")\n",
    "\n",
    "    flags.DEFINE_string(\"agent2\", \"Bot\", \"Second agent, either Bot or agent class.\")\n",
    "    flags.DEFINE_enum(\"agent2_race\", \"terran\", sc2_env.Race._member_names_,  # pylint: disable=protected-access\n",
    "                      \"Agent 2's race.\")\n",
    "    flags.DEFINE_enum(\"difficulty\", \"very_easy\", sc2_env.Difficulty._member_names_,  # pylint: disable=protected-access\n",
    "                      \"If agent2 is a built-in Bot, it's strength.\")\n",
    "\n",
    "    flags.DEFINE_bool(\"profile\", False, \"Whether to turn on code profiling.\")\n",
    "    flags.DEFINE_bool(\"trace\", False, \"Whether to trace the code execution.\")\n",
    "    flags.DEFINE_integer(\"parallel\", 1, \"How many instances to run in parallel.\")\n",
    "\n",
    "    flags.DEFINE_bool(\"save_replay\", True, \"Whether to save a replay at the end.\")\n",
    "\n",
    "    flags.DEFINE_string(\"map\", None, \"Name of a map to use.\")\n",
    "    flags.mark_flag_as_required(\"map\")\n",
    "\n",
    "flags_defined = True\n",
    "\n",
    "def run_thread(agent_classes, players, map_name, visualize):\n",
    "  \"\"\"Run one thread worth of the environment with agents.\"\"\"\n",
    "  with sc2_env.SC2Env(\n",
    "      map_name=map_name,\n",
    "      players=players,\n",
    "      agent_interface_format=sc2_env.parse_agent_interface_format(\n",
    "          feature_screen=FLAGS.feature_screen_size,\n",
    "          feature_minimap=FLAGS.feature_minimap_size,\n",
    "          rgb_screen=FLAGS.rgb_screen_size,\n",
    "          rgb_minimap=FLAGS.rgb_minimap_size,\n",
    "          action_space=FLAGS.action_space,\n",
    "          use_feature_units=FLAGS.use_feature_units),\n",
    "      step_mul=FLAGS.step_mul,\n",
    "      game_steps_per_episode=FLAGS.game_steps_per_episode,\n",
    "      disable_fog=FLAGS.disable_fog,\n",
    "      visualize=visualize) as env:\n",
    "    env = available_actions_printer.AvailableActionsPrinter(env)\n",
    "    agents = [agent_cls() for agent_cls in agent_classes]\n",
    "    run_loop.run_loop(agents, env, FLAGS.max_agent_steps, FLAGS.max_episodes)\n",
    "    if FLAGS.save_replay:\n",
    "      env.save_replay(agent_classes[0].__name__)\n",
    "\n",
    "def main(unused_argv):\n",
    "  \"\"\"Run an agent.\"\"\"\n",
    "  #stopwatch.sw.enabled = FLAGS.profile or FLAGS.trace\n",
    "  #stopwatch.sw.trace = FLAGS.trace\n",
    "\n",
    "  map_inst = maps.get(FLAGS.map)\n",
    "\n",
    "  agent_classes = []\n",
    "  players = []\n",
    "\n",
    "  #agent_module, agent_name = FLAGS.agent.rsplit(\".\", 1)\n",
    "  #agent_cls = getattr(importlib.import_module(agent_module), agent_name)\n",
    "  #agent_classes.append(agent_cls)\n",
    "  agent_classes.append(TerranSparseRewardRLAgent)\n",
    "  players.append(sc2_env.Agent(sc2_env.Race[FLAGS.agent_race]))\n",
    "\n",
    "  if map_inst.players >= 2:\n",
    "    if FLAGS.agent2 == \"Bot\":\n",
    "      players.append(sc2_env.Bot(sc2_env.Race[FLAGS.agent2_race],\n",
    "                                 sc2_env.Difficulty[FLAGS.difficulty]))\n",
    "    else:\n",
    "      agent_module, agent_name = FLAGS.agent2.rsplit(\".\", 1)\n",
    "      agent_cls = getattr(importlib.import_module(agent_module), agent_name)\n",
    "      agent_classes.append(agent_cls)\n",
    "      players.append(sc2_env.Agent(sc2_env.Race[FLAGS.agent2_race]))\n",
    "\n",
    "  threads = []\n",
    "  for _ in range(FLAGS.parallel - 1):\n",
    "    t = threading.Thread(target=run_thread,\n",
    "                         args=(agent_classes, players, FLAGS.map, False))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "  run_thread(agent_classes, players, FLAGS.map, FLAGS.render)\n",
    "\n",
    "  for t in threads:\n",
    "    t.join()\n",
    "\n",
    "  if FLAGS.profile:\n",
    "    pass\n",
    "    #print(stopwatch.sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a RL PySC2 Agent with Sparse Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pysc2.agents import base_agent\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions, features, units\n",
    "from absl import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'rlagent_with_sparse_reward_learning_data'\n",
    "\n",
    "ACTION_DO_NOTHING = 'donothing'\n",
    "ACTION_BUILD_SUPPLY_DEPOT = 'buildsupplydepot'\n",
    "ACTION_BUILD_BARRACKS = 'buildbarracks'\n",
    "ACTION_BUILD_MARINE = 'buildmarine'\n",
    "ACTION_ATTACK = 'attack'\n",
    "\n",
    "smart_actions = [\n",
    "    ACTION_DO_NOTHING,\n",
    "    ACTION_BUILD_SUPPLY_DEPOT,\n",
    "    ACTION_BUILD_BARRACKS,\n",
    "    ACTION_BUILD_MARINE,\n",
    "]\n",
    "\n",
    "for mm_x in range(0, 64):\n",
    "    for mm_y in range(0, 64):\n",
    "        if (mm_x + 1) % 32 == 0 and (mm_y + 1) % 32 == 0:\n",
    "            smart_actions.append(ACTION_ATTACK + '_' + str(mm_x - 16) + '_' + str(mm_y - 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QLearningTable 클래스 learn() 함수 수정\n",
    "\n",
    "#### Sparse Reward를 처리하기 위해 Terminal State 일때만 Reward가 발생하는 상황을 고려함.\n",
    "\n",
    "#### < AS-IS >\n",
    "    ...\n",
    "        q_predict = self.q_table.ix[s, a]\n",
    "        q_target = r + self.gamma * self.q_table.ix[s_, :].max()\n",
    "\n",
    "        # update\n",
    "        self.q_table.ix[s, a] += self.lr * (q_target - q_predict)\n",
    "    ...\n",
    "    \n",
    "#### < TO-BE >\n",
    "    ...\n",
    "        q_predict = self.q_table.ix[s, a]\n",
    "\n",
    "        if s_ != 'terminal':\n",
    "            q_target = r + self.gamma * self.q_table.loc[s_, self.q_table.columns[:]].max()\n",
    "        else:\n",
    "            q_target = r  # next state is terminal\n",
    "            \n",
    "        # update\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference from https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow\n",
    "class QLearningTable:\n",
    "    def __init__(self, actions, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9):\n",
    "        self.actions = actions  # a list\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon = e_greedy\n",
    "        self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64)\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        self.check_state_exist(observation)\n",
    "        \n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            # choose best action\n",
    "            #state_action = self.q_table.ix[observation, :]\n",
    "            state_action = self.q_table.loc[observation, self.q_table.columns[:]]\n",
    "            \n",
    "            # some actions have the same value\n",
    "            state_action = state_action.reindex(np.random.permutation(state_action.index))\n",
    "            \n",
    "            action = state_action.idxmax()\n",
    "        else:\n",
    "            # choose random action\n",
    "            action = np.random.choice(self.actions)\n",
    "            \n",
    "        return action\n",
    "\n",
    "    def learn(self, s, a, r, s_):\n",
    "        self.check_state_exist(s_)\n",
    "        self.check_state_exist(s)\n",
    "        \n",
    "        #q_predict = self.q_table.ix[s, a]\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        \n",
    "        if s_ != 'terminal':\n",
    "            #q_target = r + self.gamma * self.q_table.ix[s_, :].max()\n",
    "            q_target = r + self.gamma * self.q_table.loc[s_, self.q_table.columns[:]].max()\n",
    "        else:\n",
    "            q_target = r  # next state is terminal\n",
    "            \n",
    "        # update\n",
    "        #self.q_table.ix[s, a] += self.lr * (q_target - q_predict)\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)\n",
    "\n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            # append new state to q table\n",
    "            self.q_table = self.q_table.append(pd.Series([0] * len(self.actions), index=self.q_table.columns, name=state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerranSparseRewardRLAgent(base_agent.BaseAgent):\n",
    "    def __init__(self):\n",
    "        super(TerranSparseRewardRLAgent, self).__init__()\n",
    "        \n",
    "        self.qlearn = QLearningTable(actions=list(range(len(smart_actions))))\n",
    "        \n",
    "        self.previous_action = None\n",
    "        self.previous_state = None\n",
    "        \n",
    "        self.cc_y = None\n",
    "        self.cc_x = None\n",
    "        \n",
    "        self.move_number = 0\n",
    "        \n",
    "        if os.path.isfile(DATA_FILE + '.gz'):\n",
    "            self.qlearn.q_table = pd.read_pickle(DATA_FILE + '.gz', compression='gzip')\n",
    "\n",
    "    def transformDistance(self, x, x_distance, y, y_distance):\n",
    "        if not self.base_top_left:\n",
    "            return [x - x_distance, y - y_distance]\n",
    "        \n",
    "        return [x + x_distance, y + y_distance]\n",
    "    \n",
    "    def transformLocation(self, x, y):\n",
    "        if not self.base_top_left:\n",
    "            return [64 - x, 64 - y]\n",
    "        \n",
    "        return [x, y]\n",
    "    \n",
    "    def getMeanLocation(self, unitList):\n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        for unit in unitList:\n",
    "            sum_x += unit.x\n",
    "            sum_y += unit.y\n",
    "        mean_x = sum_x / len(unitList)\n",
    "        mean_y = sum_y / len(unitList)\n",
    "        \n",
    "        return [mean_x, mean_y]\n",
    "    \n",
    "    def splitAction(self, action_id):\n",
    "        smart_action = smart_actions[action_id]\n",
    "            \n",
    "        x = 0\n",
    "        y = 0\n",
    "        if '_' in smart_action:\n",
    "            smart_action, x, y = smart_action.split('_')\n",
    "\n",
    "        return (smart_action, x, y)\n",
    "    \n",
    "    def unit_type_is_selected(self, obs, unit_type):\n",
    "        if (len(obs.observation.single_select) > 0 and\n",
    "            obs.observation.single_select[0].unit_type == unit_type):\n",
    "              return True\n",
    "\n",
    "        if (len(obs.observation.multi_select) > 0 and\n",
    "            obs.observation.multi_select[0].unit_type == unit_type):\n",
    "              return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_units_by_type(self, obs, unit_type):\n",
    "        return [unit for unit in obs.observation.feature_units\n",
    "                if unit.unit_type == unit_type]\n",
    "\n",
    "    def can_do(self, obs, action):\n",
    "        return action in obs.observation.available_actions\n",
    "        \n",
    "    def step(self, obs):\n",
    "        super(TerranSparseRewardRLAgent, self).step(obs)\n",
    "\n",
    "        #time.sleep(0.5)\n",
    "        \n",
    "        if obs.first():\n",
    "            player_y, player_x = (obs.observation.feature_minimap.player_relative == features.PlayerRelative.SELF).nonzero()\n",
    "            self.base_top_left = 1 if player_y.any() and player_y.mean() <= 31 else 0\n",
    "            print(\"player_y: \", player_y)\n",
    "            print(\"player_y.mean(): \", player_y.mean())\n",
    "            print(\"base_top_left: \", self.base_top_left)\n",
    "            print(\"smart_actions: \", smart_actions)\n",
    "        \n",
    "        ccs = self.get_units_by_type(obs, units.Terran.CommandCenter)\n",
    "        if len(ccs) > 0:\n",
    "            self.cc_x, self.cc_y = self.getMeanLocation(ccs)\n",
    "            \n",
    "        cc_count = len(ccs)\n",
    "        \n",
    "        supply_depot_count = len(self.get_units_by_type(obs, units.Terran.SupplyDepot))\n",
    "\n",
    "        barracks_count = len(self.get_units_by_type(obs, units.Terran.Barracks))\n",
    "            \n",
    "        return actions.FUNCTIONS.no_op()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [run code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adding 1st Step of Hierarchy Actions\n",
    "\n",
    "### < Hierarchy Actions >\n",
    "#### Action Space를 줄여서 Q-table의 크기를 줄여 학습을 빠르게 하기 위함.\n",
    "\n",
    "* Do nothing — do nothing for 3 steps\n",
    "* Build supply depot — select SCV, build supply depot, send SCV to harvest minerals\n",
    "* Build barracks — select SCV, build barracks, send SCV to harvest minerals\n",
    "* Build marine — select all barracks, train marine, do nothing\n",
    "* Attack (x, y) — select army, attack coordinates, do nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pysc2.agents import base_agent\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions, features, units\n",
    "from absl import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'rlagent_with_sparse_reward_learning_data'\n",
    "\n",
    "ACTION_DO_NOTHING = 'donothing'\n",
    "ACTION_BUILD_SUPPLY_DEPOT = 'buildsupplydepot'\n",
    "ACTION_BUILD_BARRACKS = 'buildbarracks'\n",
    "ACTION_BUILD_MARINE = 'buildmarine'\n",
    "ACTION_ATTACK = 'attack'\n",
    "\n",
    "smart_actions = [\n",
    "    ACTION_DO_NOTHING,\n",
    "    ACTION_BUILD_SUPPLY_DEPOT,\n",
    "    ACTION_BUILD_BARRACKS,\n",
    "    ACTION_BUILD_MARINE,\n",
    "]\n",
    "\n",
    "for mm_x in range(0, 64):\n",
    "    for mm_y in range(0, 64):\n",
    "        if (mm_x + 1) % 32 == 0 and (mm_y + 1) % 32 == 0:\n",
    "            smart_actions.append(ACTION_ATTACK + '_' + str(mm_x - 16) + '_' + str(mm_y - 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference from https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow\n",
    "class QLearningTable:\n",
    "    def __init__(self, actions, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9):\n",
    "        self.actions = actions  # a list\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon = e_greedy\n",
    "        self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64)\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        self.check_state_exist(observation)\n",
    "        \n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            # choose best action\n",
    "            #state_action = self.q_table.ix[observation, :]\n",
    "            state_action = self.q_table.loc[observation, self.q_table.columns[:]]\n",
    "            \n",
    "            # some actions have the same value\n",
    "            state_action = state_action.reindex(np.random.permutation(state_action.index))\n",
    "            \n",
    "            action = state_action.idxmax()\n",
    "        else:\n",
    "            # choose random action\n",
    "            action = np.random.choice(self.actions)\n",
    "            \n",
    "        return action\n",
    "\n",
    "    def learn(self, s, a, r, s_):\n",
    "        self.check_state_exist(s_)\n",
    "        self.check_state_exist(s)\n",
    "        \n",
    "        #q_predict = self.q_table.ix[s, a]\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        \n",
    "        if s_ != 'terminal':\n",
    "            #q_target = r + self.gamma * self.q_table.ix[s_, :].max()\n",
    "            q_target = r + self.gamma * self.q_table.loc[s_, self.q_table.columns[:]].max()\n",
    "        else:\n",
    "            q_target = r  # next state is terminal\n",
    "            \n",
    "        # update\n",
    "        #self.q_table.ix[s, a] += self.lr * (q_target - q_predict)\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)\n",
    "\n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            # append new state to q table\n",
    "            self.q_table = self.q_table.append(pd.Series([0] * len(self.actions), index=self.q_table.columns, name=state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerranSparseRewardRLAgent(base_agent.BaseAgent):\n",
    "    def __init__(self):\n",
    "        super(TerranSparseRewardRLAgent, self).__init__()\n",
    "        \n",
    "        self.qlearn = QLearningTable(actions=list(range(len(smart_actions))))\n",
    "        \n",
    "        self.previous_action = None\n",
    "        self.previous_state = None\n",
    "        \n",
    "        self.cc_y = None\n",
    "        self.cc_x = None\n",
    "        \n",
    "        self.move_number = 0\n",
    "        \n",
    "        if os.path.isfile(DATA_FILE + '.gz'):\n",
    "            self.qlearn.q_table = pd.read_pickle(DATA_FILE + '.gz', compression='gzip')\n",
    "\n",
    "    def transformDistance(self, x, x_distance, y, y_distance):\n",
    "        if not self.base_top_left:\n",
    "            return [x - x_distance, y - y_distance]\n",
    "        \n",
    "        return [x + x_distance, y + y_distance]\n",
    "    \n",
    "    def transformLocation(self, x, y):\n",
    "        if not self.base_top_left:\n",
    "            return [64 - x, 64 - y]\n",
    "        \n",
    "        return [x, y]\n",
    "    \n",
    "    def getMeanLocation(self, unitList):\n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        for unit in unitList:\n",
    "            sum_x += unit.x\n",
    "            sum_y += unit.y\n",
    "        mean_x = sum_x / len(unitList)\n",
    "        mean_y = sum_y / len(unitList)\n",
    "        \n",
    "        return [mean_x, mean_y]\n",
    "    \n",
    "    def splitAction(self, action_id):\n",
    "        smart_action = smart_actions[action_id]\n",
    "            \n",
    "        x = 0\n",
    "        y = 0\n",
    "        if '_' in smart_action:\n",
    "            smart_action, x, y = smart_action.split('_')\n",
    "\n",
    "        return (smart_action, x, y)\n",
    "    \n",
    "    def unit_type_is_selected(self, obs, unit_type):\n",
    "        if (len(obs.observation.single_select) > 0 and\n",
    "            obs.observation.single_select[0].unit_type == unit_type):\n",
    "              return True\n",
    "\n",
    "        if (len(obs.observation.multi_select) > 0 and\n",
    "            obs.observation.multi_select[0].unit_type == unit_type):\n",
    "              return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_units_by_type(self, obs, unit_type):\n",
    "        return [unit for unit in obs.observation.feature_units\n",
    "                if unit.unit_type == unit_type]\n",
    "\n",
    "    def can_do(self, obs, action):\n",
    "        return action in obs.observation.available_actions\n",
    "        \n",
    "    def step(self, obs):\n",
    "        super(TerranSparseRewardRLAgent, self).step(obs)\n",
    "\n",
    "        #time.sleep(0.5)\n",
    "        \n",
    "        if obs.first():\n",
    "            player_y, player_x = (obs.observation.feature_minimap.player_relative == features.PlayerRelative.SELF).nonzero()\n",
    "            self.base_top_left = 1 if player_y.any() and player_y.mean() <= 31 else 0\n",
    "        \n",
    "        ccs = self.get_units_by_type(obs, units.Terran.CommandCenter)\n",
    "        if len(ccs) > 0:\n",
    "            self.cc_x, self.cc_y = self.getMeanLocation(ccs)\n",
    "            \n",
    "        cc_count = len(ccs)\n",
    "        \n",
    "        supply_depot_count = len(self.get_units_by_type(obs, units.Terran.SupplyDepot))\n",
    "\n",
    "        barracks_count = len(self.get_units_by_type(obs, units.Terran.Barracks))\n",
    "\n",
    "        army_supply = obs.observation.player.food_used\n",
    "        \n",
    "        if self.move_number == 0:\n",
    "            self.move_number += 1\n",
    "            \n",
    "            current_state = np.zeros(8)\n",
    "            current_state[0] = cc_count\n",
    "            current_state[1] = supply_depot_count\n",
    "            current_state[2] = barracks_count\n",
    "            current_state[3] = army_supply\n",
    "    \n",
    "            hot_squares = np.zeros(4)        \n",
    "            enemy_y, enemy_x = (obs.observation.feature_minimap.player_relative == features.PlayerRelative.ENEMY).nonzero()\n",
    "            for i in range(0, len(enemy_y)):\n",
    "                y = int(math.ceil((enemy_y[i] + 1) / 32))\n",
    "                x = int(math.ceil((enemy_x[i] + 1) / 32))\n",
    "                \n",
    "                hot_squares[((y - 1) * 2) + (x - 1)] = 1\n",
    "            \n",
    "            if not self.base_top_left:\n",
    "                hot_squares = hot_squares[::-1]\n",
    "            \n",
    "            for i in range(0, 4):\n",
    "                current_state[i + 4] = hot_squares[i]\n",
    "    \n",
    "            if self.previous_action is not None:\n",
    "                self.qlearn.learn(str(self.previous_state), self.previous_action, 0, str(current_state))\n",
    "        \n",
    "            rl_action = self.qlearn.choose_action(str(current_state))\n",
    "\n",
    "            self.previous_state = current_state\n",
    "            self.previous_action = rl_action\n",
    "        \n",
    "            smart_action, x, y = self.splitAction(self.previous_action)\n",
    "            \n",
    "            if smart_action == ACTION_BUILD_BARRACKS or smart_action == ACTION_BUILD_SUPPLY_DEPOT:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_point.id):\n",
    "                    scvs = self.get_units_by_type(obs, units.Terran.SCV)\n",
    "                    if len(scvs) > 0:\n",
    "                        scv = random.choice(scvs)\n",
    "                        if scv.x >= 0 and scv.y >= 0:\n",
    "                            return actions.FUNCTIONS.select_point(\"select\", (scv.x,\n",
    "                                                                              scv.y))\n",
    "                \n",
    "            elif smart_action == ACTION_BUILD_MARINE:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_point.id):\n",
    "                    barracks = self.get_units_by_type(obs, units.Terran.Barracks)\n",
    "                    if len(barracks) > 0:\n",
    "                        barrack = random.choice(barracks)\n",
    "                        if barrack.x >= 0 and barrack.y >= 0:\n",
    "                            return actions.FUNCTIONS.select_point(\"select_all_type\", (barrack.x,\n",
    "                                                                                  barrack.y))\n",
    "                \n",
    "            elif smart_action == ACTION_ATTACK:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_army.id):\n",
    "                    return actions.FUNCTIONS.select_army(\"select\")\n",
    "        \n",
    "        return actions.FUNCTIONS.no_op()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [run code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adding 2nd Step of Hierarchy Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pysc2.agents import base_agent\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions, features, units\n",
    "from absl import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'rlagent_with_sparse_reward_learning_data'\n",
    "\n",
    "ACTION_DO_NOTHING = 'donothing'\n",
    "ACTION_BUILD_SUPPLY_DEPOT = 'buildsupplydepot'\n",
    "ACTION_BUILD_BARRACKS = 'buildbarracks'\n",
    "ACTION_BUILD_MARINE = 'buildmarine'\n",
    "ACTION_ATTACK = 'attack'\n",
    "\n",
    "smart_actions = [\n",
    "    ACTION_DO_NOTHING,\n",
    "    ACTION_BUILD_SUPPLY_DEPOT,\n",
    "    ACTION_BUILD_BARRACKS,\n",
    "    ACTION_BUILD_MARINE,\n",
    "]\n",
    "\n",
    "for mm_x in range(0, 64):\n",
    "    for mm_y in range(0, 64):\n",
    "        if (mm_x + 1) % 32 == 0 and (mm_y + 1) % 32 == 0:\n",
    "            smart_actions.append(ACTION_ATTACK + '_' + str(mm_x - 16) + '_' + str(mm_y - 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference from https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow\n",
    "class QLearningTable:\n",
    "    def __init__(self, actions, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9):\n",
    "        self.actions = actions  # a list\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon = e_greedy\n",
    "        self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64)\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        self.check_state_exist(observation)\n",
    "        \n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            # choose best action\n",
    "            #state_action = self.q_table.ix[observation, :]\n",
    "            state_action = self.q_table.loc[observation, self.q_table.columns[:]]\n",
    "            \n",
    "            # some actions have the same value\n",
    "            state_action = state_action.reindex(np.random.permutation(state_action.index))\n",
    "            \n",
    "            action = state_action.idxmax()\n",
    "        else:\n",
    "            # choose random action\n",
    "            action = np.random.choice(self.actions)\n",
    "            \n",
    "        return action\n",
    "\n",
    "    def learn(self, s, a, r, s_):\n",
    "        self.check_state_exist(s_)\n",
    "        self.check_state_exist(s)\n",
    "        \n",
    "        #q_predict = self.q_table.ix[s, a]\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        \n",
    "        if s_ != 'terminal':\n",
    "            #q_target = r + self.gamma * self.q_table.ix[s_, :].max()\n",
    "            q_target = r + self.gamma * self.q_table.loc[s_, self.q_table.columns[:]].max()\n",
    "        else:\n",
    "            q_target = r  # next state is terminal\n",
    "            \n",
    "        # update\n",
    "        #self.q_table.ix[s, a] += self.lr * (q_target - q_predict)\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)\n",
    "\n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            # append new state to q table\n",
    "            self.q_table = self.q_table.append(pd.Series([0] * len(self.actions), index=self.q_table.columns, name=state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerranSparseRewardRLAgent(base_agent.BaseAgent):\n",
    "    def __init__(self):\n",
    "        super(TerranSparseRewardRLAgent, self).__init__()\n",
    "        \n",
    "        self.qlearn = QLearningTable(actions=list(range(len(smart_actions))))\n",
    "        \n",
    "        self.previous_action = None\n",
    "        self.previous_state = None\n",
    "        \n",
    "        self.cc_y = None\n",
    "        self.cc_x = None\n",
    "        \n",
    "        self.move_number = 0\n",
    "        \n",
    "        if os.path.isfile(DATA_FILE + '.gz'):\n",
    "            self.qlearn.q_table = pd.read_pickle(DATA_FILE + '.gz', compression='gzip')\n",
    "\n",
    "    def transformDistance(self, x, x_distance, y, y_distance):\n",
    "        if not self.base_top_left:\n",
    "            return [x - x_distance, y - y_distance]\n",
    "        \n",
    "        return [x + x_distance, y + y_distance]\n",
    "    \n",
    "    def transformLocation(self, x, y):\n",
    "        if not self.base_top_left:\n",
    "            return [64 - x, 64 - y]\n",
    "        \n",
    "        return [x, y]\n",
    "    \n",
    "    def getMeanLocation(self, unitList):\n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        for unit in unitList:\n",
    "            sum_x += unit.x\n",
    "            sum_y += unit.y\n",
    "        mean_x = sum_x / len(unitList)\n",
    "        mean_y = sum_y / len(unitList)\n",
    "        \n",
    "        return [mean_x, mean_y]\n",
    "    \n",
    "    def splitAction(self, action_id):\n",
    "        smart_action = smart_actions[action_id]\n",
    "            \n",
    "        x = 0\n",
    "        y = 0\n",
    "        if '_' in smart_action:\n",
    "            smart_action, x, y = smart_action.split('_')\n",
    "\n",
    "        return (smart_action, x, y)\n",
    "    \n",
    "    def unit_type_is_selected(self, obs, unit_type):\n",
    "        if (len(obs.observation.single_select) > 0 and\n",
    "            obs.observation.single_select[0].unit_type == unit_type):\n",
    "              return True\n",
    "\n",
    "        if (len(obs.observation.multi_select) > 0 and\n",
    "            obs.observation.multi_select[0].unit_type == unit_type):\n",
    "              return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_units_by_type(self, obs, unit_type):\n",
    "        return [unit for unit in obs.observation.feature_units\n",
    "                if unit.unit_type == unit_type]\n",
    "\n",
    "    def can_do(self, obs, action):\n",
    "        return action in obs.observation.available_actions\n",
    "        \n",
    "    def step(self, obs):\n",
    "        super(TerranSparseRewardRLAgent, self).step(obs)\n",
    "\n",
    "        #time.sleep(0.5)\n",
    "        \n",
    "        if obs.first():\n",
    "            player_y, player_x = (obs.observation.feature_minimap.player_relative == features.PlayerRelative.SELF).nonzero()\n",
    "            self.base_top_left = 1 if player_y.any() and player_y.mean() <= 31 else 0\n",
    "        \n",
    "        ccs = self.get_units_by_type(obs, units.Terran.CommandCenter)\n",
    "        if len(ccs) > 0:\n",
    "            self.cc_x, self.cc_y = self.getMeanLocation(ccs)\n",
    "            \n",
    "        cc_count = len(ccs)\n",
    "        \n",
    "        supply_depot_count = len(self.get_units_by_type(obs, units.Terran.SupplyDepot))\n",
    "\n",
    "        barracks_count = len(self.get_units_by_type(obs, units.Terran.Barracks))\n",
    "\n",
    "        army_supply = obs.observation.player.food_used\n",
    "        \n",
    "        if self.move_number == 0:\n",
    "            self.move_number += 1\n",
    "            \n",
    "            current_state = np.zeros(8)\n",
    "            current_state[0] = cc_count\n",
    "            current_state[1] = supply_depot_count\n",
    "            current_state[2] = barracks_count\n",
    "            current_state[3] = army_supply\n",
    "    \n",
    "            hot_squares = np.zeros(4)        \n",
    "            enemy_y, enemy_x = (obs.observation.feature_minimap.player_relative == features.PlayerRelative.ENEMY).nonzero()\n",
    "            for i in range(0, len(enemy_y)):\n",
    "                y = int(math.ceil((enemy_y[i] + 1) / 32))\n",
    "                x = int(math.ceil((enemy_x[i] + 1) / 32))\n",
    "                \n",
    "                hot_squares[((y - 1) * 2) + (x - 1)] = 1\n",
    "            \n",
    "            if not self.base_top_left:\n",
    "                hot_squares = hot_squares[::-1]\n",
    "            \n",
    "            for i in range(0, 4):\n",
    "                current_state[i + 4] = hot_squares[i]\n",
    "    \n",
    "            if self.previous_action is not None:\n",
    "                self.qlearn.learn(str(self.previous_state), self.previous_action, 0, str(current_state))\n",
    "        \n",
    "            rl_action = self.qlearn.choose_action(str(current_state))\n",
    "\n",
    "            self.previous_state = current_state\n",
    "            self.previous_action = rl_action\n",
    "        \n",
    "            smart_action, x, y = self.splitAction(self.previous_action)\n",
    "            \n",
    "            if smart_action == ACTION_BUILD_BARRACKS or smart_action == ACTION_BUILD_SUPPLY_DEPOT:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_point.id):\n",
    "                    scvs = self.get_units_by_type(obs, units.Terran.SCV)\n",
    "                    if len(scvs) > 0:\n",
    "                        scv = random.choice(scvs)\n",
    "                        if scv.x >= 0 and scv.y >= 0:\n",
    "                            return actions.FUNCTIONS.select_point(\"select\", (scv.x,\n",
    "                                                                              scv.y))\n",
    "                \n",
    "            elif smart_action == ACTION_BUILD_MARINE:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_point.id):\n",
    "                    barracks = self.get_units_by_type(obs, units.Terran.Barracks)\n",
    "                    if len(barracks) > 0:\n",
    "                        barrack = random.choice(barracks)\n",
    "                        if barrack.x >= 0 and barrack.y >= 0:\n",
    "                            return actions.FUNCTIONS.select_point(\"select_all_type\", (barrack.x,\n",
    "                                                                                  barrack.y))\n",
    "                \n",
    "            elif smart_action == ACTION_ATTACK:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_army.id):\n",
    "                    return actions.FUNCTIONS.select_army(\"select\")\n",
    "                \n",
    "        elif self.move_number == 1:\n",
    "            self.move_number += 1\n",
    "            \n",
    "            smart_action, x, y = self.splitAction(self.previous_action)\n",
    "                \n",
    "            if smart_action == ACTION_BUILD_SUPPLY_DEPOT:\n",
    "                if supply_depot_count < 2 and self.can_do(obs, actions.FUNCTIONS.Build_SupplyDepot_screen.id):\n",
    "                    if len(ccs) > 0:\n",
    "                        if supply_depot_count == 0:\n",
    "                            target = self.transformDistance(self.cc_x, -35, self.cc_y, 0)\n",
    "                        elif supply_depot_count == 1:\n",
    "                            target = self.transformDistance(self.cc_x, -25, self.cc_y, -25)\n",
    "    \n",
    "                        return actions.FUNCTIONS.Build_SupplyDepot_screen(\"now\", target) \n",
    "            \n",
    "            elif smart_action == ACTION_BUILD_BARRACKS:\n",
    "                if barracks_count < 2 and self.can_do(obs, actions.FUNCTIONS.Build_Barracks_screen.id):\n",
    "                    if len(ccs) > 0:\n",
    "                        if  barracks_count == 0:\n",
    "                            target = self.transformDistance(self.cc_x, 15, self.cc_y, -9)\n",
    "                        elif  barracks_count == 1:\n",
    "                            target = self.transformDistance(self.cc_x, 15, self.cc_y, 12)\n",
    "    \n",
    "                        return actions.FUNCTIONS.Build_Barracks_screen(\"now\", target)\n",
    "    \n",
    "            elif smart_action == ACTION_BUILD_MARINE:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.Train_Marine_quick.id):\n",
    "                    return actions.FUNCTIONS.Train_Marine_quick(\"queued\")\n",
    "        \n",
    "            elif smart_action == ACTION_ATTACK:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.Attack_minimap.id):\n",
    "                    x_offset = random.randint(-1, 1)\n",
    "                    y_offset = random.randint(-1, 1)\n",
    "                    \n",
    "                    return actions.FUNCTIONS.Attack_minimap(\"now\", self.transformLocation(int(x) + (x_offset * 8), int(y) + (y_offset * 8)))\n",
    "            \n",
    "        return actions.FUNCTIONS.no_op()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [run code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adding 3rd Step of Hierarchy Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pysc2.agents import base_agent\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions, features, units\n",
    "from absl import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'rlagent_with_sparse_reward_learning_data'\n",
    "\n",
    "ACTION_DO_NOTHING = 'donothing'\n",
    "ACTION_BUILD_SUPPLY_DEPOT = 'buildsupplydepot'\n",
    "ACTION_BUILD_BARRACKS = 'buildbarracks'\n",
    "ACTION_BUILD_MARINE = 'buildmarine'\n",
    "ACTION_ATTACK = 'attack'\n",
    "\n",
    "smart_actions = [\n",
    "    ACTION_DO_NOTHING,\n",
    "    ACTION_BUILD_SUPPLY_DEPOT,\n",
    "    ACTION_BUILD_BARRACKS,\n",
    "    ACTION_BUILD_MARINE,\n",
    "]\n",
    "\n",
    "for mm_x in range(0, 64):\n",
    "    for mm_y in range(0, 64):\n",
    "        if (mm_x + 1) % 32 == 0 and (mm_y + 1) % 32 == 0:\n",
    "            smart_actions.append(ACTION_ATTACK + '_' + str(mm_x - 16) + '_' + str(mm_y - 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference from https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow\n",
    "class QLearningTable:\n",
    "    def __init__(self, actions, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9):\n",
    "        self.actions = actions  # a list\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon = e_greedy\n",
    "        self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64)\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        self.check_state_exist(observation)\n",
    "        \n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            # choose best action\n",
    "            #state_action = self.q_table.ix[observation, :]\n",
    "            state_action = self.q_table.loc[observation, self.q_table.columns[:]]\n",
    "            \n",
    "            # some actions have the same value\n",
    "            state_action = state_action.reindex(np.random.permutation(state_action.index))\n",
    "            \n",
    "            action = state_action.idxmax()\n",
    "        else:\n",
    "            # choose random action\n",
    "            action = np.random.choice(self.actions)\n",
    "            \n",
    "        return action\n",
    "\n",
    "    def learn(self, s, a, r, s_):\n",
    "        self.check_state_exist(s_)\n",
    "        self.check_state_exist(s)\n",
    "        \n",
    "        #q_predict = self.q_table.ix[s, a]\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        \n",
    "        if s_ != 'terminal':\n",
    "            #q_target = r + self.gamma * self.q_table.ix[s_, :].max()\n",
    "            q_target = r + self.gamma * self.q_table.loc[s_, self.q_table.columns[:]].max()\n",
    "        else:\n",
    "            q_target = r  # next state is terminal\n",
    "            \n",
    "        # update\n",
    "        #self.q_table.ix[s, a] += self.lr * (q_target - q_predict)\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)\n",
    "\n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            # append new state to q table\n",
    "            self.q_table = self.q_table.append(pd.Series([0] * len(self.actions), index=self.q_table.columns, name=state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerranSparseRewardRLAgent(base_agent.BaseAgent):\n",
    "    def __init__(self):\n",
    "        super(TerranSparseRewardRLAgent, self).__init__()\n",
    "        \n",
    "        self.qlearn = QLearningTable(actions=list(range(len(smart_actions))))\n",
    "        \n",
    "        self.previous_action = None\n",
    "        self.previous_state = None\n",
    "        \n",
    "        self.cc_y = None\n",
    "        self.cc_x = None\n",
    "        \n",
    "        self.move_number = 0\n",
    "        \n",
    "        if os.path.isfile(DATA_FILE + '.gz'):\n",
    "            self.qlearn.q_table = pd.read_pickle(DATA_FILE + '.gz', compression='gzip')\n",
    "\n",
    "    def transformDistance(self, x, x_distance, y, y_distance):\n",
    "        if not self.base_top_left:\n",
    "            return [x - x_distance, y - y_distance]\n",
    "        \n",
    "        return [x + x_distance, y + y_distance]\n",
    "    \n",
    "    def transformLocation(self, x, y):\n",
    "        if not self.base_top_left:\n",
    "            return [64 - x, 64 - y]\n",
    "        \n",
    "        return [x, y]\n",
    "    \n",
    "    def getMeanLocation(self, unitList):\n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        for unit in unitList:\n",
    "            sum_x += unit.x\n",
    "            sum_y += unit.y\n",
    "        mean_x = sum_x / len(unitList)\n",
    "        mean_y = sum_y / len(unitList)\n",
    "        \n",
    "        return [mean_x, mean_y]\n",
    "    \n",
    "    def splitAction(self, action_id):\n",
    "        smart_action = smart_actions[action_id]\n",
    "            \n",
    "        x = 0\n",
    "        y = 0\n",
    "        if '_' in smart_action:\n",
    "            smart_action, x, y = smart_action.split('_')\n",
    "\n",
    "        return (smart_action, x, y)\n",
    "    \n",
    "    def unit_type_is_selected(self, obs, unit_type):\n",
    "        if (len(obs.observation.single_select) > 0 and\n",
    "            obs.observation.single_select[0].unit_type == unit_type):\n",
    "              return True\n",
    "\n",
    "        if (len(obs.observation.multi_select) > 0 and\n",
    "            obs.observation.multi_select[0].unit_type == unit_type):\n",
    "              return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_units_by_type(self, obs, unit_type):\n",
    "        return [unit for unit in obs.observation.feature_units\n",
    "                if unit.unit_type == unit_type]\n",
    "\n",
    "    def can_do(self, obs, action):\n",
    "        return action in obs.observation.available_actions\n",
    "        \n",
    "    def step(self, obs):\n",
    "        super(TerranSparseRewardRLAgent, self).step(obs)\n",
    "\n",
    "        #time.sleep(0.5)\n",
    "        \n",
    "        if obs.first():\n",
    "            player_y, player_x = (obs.observation.feature_minimap.player_relative == features.PlayerRelative.SELF).nonzero()\n",
    "            self.base_top_left = 1 if player_y.any() and player_y.mean() <= 31 else 0\n",
    "        \n",
    "        ccs = self.get_units_by_type(obs, units.Terran.CommandCenter)\n",
    "        if len(ccs) > 0:\n",
    "            self.cc_x, self.cc_y = self.getMeanLocation(ccs)\n",
    "            \n",
    "        cc_count = len(ccs)\n",
    "        \n",
    "        supply_depot_count = len(self.get_units_by_type(obs, units.Terran.SupplyDepot))\n",
    "\n",
    "        barracks_count = len(self.get_units_by_type(obs, units.Terran.Barracks))\n",
    "\n",
    "        army_supply = obs.observation.player.food_used\n",
    "        \n",
    "        if self.move_number == 0:\n",
    "            self.move_number += 1\n",
    "            \n",
    "            current_state = np.zeros(8)\n",
    "            current_state[0] = cc_count\n",
    "            current_state[1] = supply_depot_count\n",
    "            current_state[2] = barracks_count\n",
    "            current_state[3] = army_supply\n",
    "    \n",
    "            hot_squares = np.zeros(4)        \n",
    "            enemy_y, enemy_x = (obs.observation.feature_minimap.player_relative == features.PlayerRelative.ENEMY).nonzero()\n",
    "            for i in range(0, len(enemy_y)):\n",
    "                y = int(math.ceil((enemy_y[i] + 1) / 32))\n",
    "                x = int(math.ceil((enemy_x[i] + 1) / 32))\n",
    "                \n",
    "                hot_squares[((y - 1) * 2) + (x - 1)] = 1\n",
    "            \n",
    "            if not self.base_top_left:\n",
    "                hot_squares = hot_squares[::-1]\n",
    "            \n",
    "            for i in range(0, 4):\n",
    "                current_state[i + 4] = hot_squares[i]\n",
    "    \n",
    "            if self.previous_action is not None:\n",
    "                self.qlearn.learn(str(self.previous_state), self.previous_action, 0, str(current_state))\n",
    "        \n",
    "            rl_action = self.qlearn.choose_action(str(current_state))\n",
    "\n",
    "            self.previous_state = current_state\n",
    "            self.previous_action = rl_action\n",
    "        \n",
    "            smart_action, x, y = self.splitAction(self.previous_action)\n",
    "            \n",
    "            if smart_action == ACTION_BUILD_BARRACKS or smart_action == ACTION_BUILD_SUPPLY_DEPOT:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_point.id):\n",
    "                    scvs = self.get_units_by_type(obs, units.Terran.SCV)\n",
    "                    if len(scvs) > 0:\n",
    "                        scv = random.choice(scvs)\n",
    "                        if scv.x >= 0 and scv.y >= 0:\n",
    "                            return actions.FUNCTIONS.select_point(\"select\", (scv.x,\n",
    "                                                                              scv.y))\n",
    "                \n",
    "            elif smart_action == ACTION_BUILD_MARINE:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_point.id):\n",
    "                    barracks = self.get_units_by_type(obs, units.Terran.Barracks)\n",
    "                    if len(barracks) > 0:\n",
    "                        barrack = random.choice(barracks)\n",
    "                        if barrack.x >= 0 and barrack.y >= 0:\n",
    "                            return actions.FUNCTIONS.select_point(\"select_all_type\", (barrack.x,\n",
    "                                                                                  barrack.y))\n",
    "                \n",
    "            elif smart_action == ACTION_ATTACK:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_army.id):\n",
    "                    return actions.FUNCTIONS.select_army(\"select\")\n",
    "                \n",
    "        elif self.move_number == 1:\n",
    "            self.move_number += 1\n",
    "            \n",
    "            smart_action, x, y = self.splitAction(self.previous_action)\n",
    "                \n",
    "            if smart_action == ACTION_BUILD_SUPPLY_DEPOT:\n",
    "                if supply_depot_count < 2 and self.can_do(obs, actions.FUNCTIONS.Build_SupplyDepot_screen.id):\n",
    "                    if len(ccs) > 0:\n",
    "                        if supply_depot_count == 0:\n",
    "                            target = self.transformDistance(self.cc_x, -35, self.cc_y, 0)\n",
    "                        elif supply_depot_count == 1:\n",
    "                            target = self.transformDistance(self.cc_x, -25, self.cc_y, -25)\n",
    "    \n",
    "                        return actions.FUNCTIONS.Build_SupplyDepot_screen(\"now\", target) \n",
    "            \n",
    "            elif smart_action == ACTION_BUILD_BARRACKS:\n",
    "                if barracks_count < 2 and self.can_do(obs, actions.FUNCTIONS.Build_Barracks_screen.id):\n",
    "                    if len(ccs) > 0:\n",
    "                        if  barracks_count == 0:\n",
    "                            target = self.transformDistance(self.cc_x, 15, self.cc_y, -9)\n",
    "                        elif  barracks_count == 1:\n",
    "                            target = self.transformDistance(self.cc_x, 15, self.cc_y, 12)\n",
    "    \n",
    "                        return actions.FUNCTIONS.Build_Barracks_screen(\"now\", target)\n",
    "    \n",
    "            elif smart_action == ACTION_BUILD_MARINE:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.Train_Marine_quick.id):\n",
    "                    return actions.FUNCTIONS.Train_Marine_quick(\"queued\")\n",
    "        \n",
    "            elif smart_action == ACTION_ATTACK:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.Attack_minimap.id):\n",
    "                    x_offset = random.randint(-1, 1)\n",
    "                    y_offset = random.randint(-1, 1)\n",
    "                    \n",
    "                    return actions.FUNCTIONS.Attack_minimap(\"now\", self.transformLocation(int(x) + (x_offset * 8), int(y) + (y_offset * 8)))\n",
    "            \n",
    "        elif self.move_number == 2:\n",
    "            self.move_number = 0\n",
    "            \n",
    "            smart_action, x, y = self.splitAction(self.previous_action)\n",
    "                \n",
    "            if smart_action == ACTION_BUILD_BARRACKS or smart_action == ACTION_BUILD_SUPPLY_DEPOT:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.Harvest_Gather_screen.id):\n",
    "                    mfs = self.get_units_by_type(obs, units.Neutral.MineralField)\n",
    "                    if len(mfs) > 0:\n",
    "                        mf = random.choice(mfs)\n",
    "                        if mf.x >= 0 and mf.y >= 0:\n",
    "                            return actions.FUNCTIONS.Harvest_Gather_screen(\"now\", (mf.x,mf.y))\n",
    "            \n",
    "        return actions.FUNCTIONS.no_op()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [run code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detecting End of Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pysc2.agents import base_agent\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions, features, units\n",
    "from absl import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'rlagent_with_sparse_reward_learning_data'\n",
    "\n",
    "ACTION_DO_NOTHING = 'donothing'\n",
    "ACTION_BUILD_SUPPLY_DEPOT = 'buildsupplydepot'\n",
    "ACTION_BUILD_BARRACKS = 'buildbarracks'\n",
    "ACTION_BUILD_MARINE = 'buildmarine'\n",
    "ACTION_ATTACK = 'attack'\n",
    "\n",
    "smart_actions = [\n",
    "    ACTION_DO_NOTHING,\n",
    "    ACTION_BUILD_SUPPLY_DEPOT,\n",
    "    ACTION_BUILD_BARRACKS,\n",
    "    ACTION_BUILD_MARINE,\n",
    "]\n",
    "\n",
    "for mm_x in range(0, 64):\n",
    "    for mm_y in range(0, 64):\n",
    "        if (mm_x + 1) % 32 == 0 and (mm_y + 1) % 32 == 0:\n",
    "            smart_actions.append(ACTION_ATTACK + '_' + str(mm_x - 16) + '_' + str(mm_y - 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference from https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow\n",
    "class QLearningTable:\n",
    "    def __init__(self, actions, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9):\n",
    "        self.actions = actions  # a list\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon = e_greedy\n",
    "        self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64)\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        self.check_state_exist(observation)\n",
    "        \n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            # choose best action\n",
    "            #state_action = self.q_table.ix[observation, :]\n",
    "            state_action = self.q_table.loc[observation, self.q_table.columns[:]]\n",
    "            \n",
    "            # some actions have the same value\n",
    "            state_action = state_action.reindex(np.random.permutation(state_action.index))\n",
    "            \n",
    "            action = state_action.idxmax()\n",
    "        else:\n",
    "            # choose random action\n",
    "            action = np.random.choice(self.actions)\n",
    "            \n",
    "        return action\n",
    "\n",
    "    def learn(self, s, a, r, s_):\n",
    "        self.check_state_exist(s_)\n",
    "        self.check_state_exist(s)\n",
    "        \n",
    "        #q_predict = self.q_table.ix[s, a]\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        \n",
    "        if s_ != 'terminal':\n",
    "            #q_target = r + self.gamma * self.q_table.ix[s_, :].max()\n",
    "            q_target = r + self.gamma * self.q_table.loc[s_, self.q_table.columns[:]].max()\n",
    "        else:\n",
    "            q_target = r  # next state is terminal\n",
    "            \n",
    "        # update\n",
    "        #self.q_table.ix[s, a] += self.lr * (q_target - q_predict)\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)\n",
    "\n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            # append new state to q table\n",
    "            self.q_table = self.q_table.append(pd.Series([0] * len(self.actions), index=self.q_table.columns, name=state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerranSparseRewardRLAgent(base_agent.BaseAgent):\n",
    "    def __init__(self):\n",
    "        super(TerranSparseRewardRLAgent, self).__init__()\n",
    "        \n",
    "        self.qlearn = QLearningTable(actions=list(range(len(smart_actions))))\n",
    "        \n",
    "        self.previous_action = None\n",
    "        self.previous_state = None\n",
    "        \n",
    "        self.cc_y = None\n",
    "        self.cc_x = None\n",
    "        \n",
    "        self.move_number = 0\n",
    "        \n",
    "        if os.path.isfile(DATA_FILE + '.gz'):\n",
    "            self.qlearn.q_table = pd.read_pickle(DATA_FILE + '.gz', compression='gzip')\n",
    "\n",
    "    def transformDistance(self, x, x_distance, y, y_distance):\n",
    "        if not self.base_top_left:\n",
    "            return [x - x_distance, y - y_distance]\n",
    "        \n",
    "        return [x + x_distance, y + y_distance]\n",
    "    \n",
    "    def transformLocation(self, x, y):\n",
    "        if not self.base_top_left:\n",
    "            return [64 - x, 64 - y]\n",
    "        \n",
    "        return [x, y]\n",
    "    \n",
    "    def getMeanLocation(self, unitList):\n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        for unit in unitList:\n",
    "            sum_x += unit.x\n",
    "            sum_y += unit.y\n",
    "        mean_x = sum_x / len(unitList)\n",
    "        mean_y = sum_y / len(unitList)\n",
    "        \n",
    "        return [mean_x, mean_y]\n",
    "    \n",
    "    def splitAction(self, action_id):\n",
    "        smart_action = smart_actions[action_id]\n",
    "            \n",
    "        x = 0\n",
    "        y = 0\n",
    "        if '_' in smart_action:\n",
    "            smart_action, x, y = smart_action.split('_')\n",
    "\n",
    "        return (smart_action, x, y)\n",
    "    \n",
    "    def unit_type_is_selected(self, obs, unit_type):\n",
    "        if (len(obs.observation.single_select) > 0 and\n",
    "            obs.observation.single_select[0].unit_type == unit_type):\n",
    "              return True\n",
    "\n",
    "        if (len(obs.observation.multi_select) > 0 and\n",
    "            obs.observation.multi_select[0].unit_type == unit_type):\n",
    "              return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_units_by_type(self, obs, unit_type):\n",
    "        return [unit for unit in obs.observation.feature_units\n",
    "                if unit.unit_type == unit_type]\n",
    "\n",
    "    def can_do(self, obs, action):\n",
    "        return action in obs.observation.available_actions\n",
    "        \n",
    "    def step(self, obs):\n",
    "        super(TerranSparseRewardRLAgent, self).step(obs)\n",
    "\n",
    "        #time.sleep(0.5)\n",
    "        \n",
    "        if obs.last():\n",
    "            reward = obs.reward\n",
    "        \n",
    "            self.qlearn.learn(str(self.previous_state), self.previous_action, reward, 'terminal')\n",
    "            \n",
    "            self.qlearn.q_table.to_pickle(DATA_FILE + '.gz', 'gzip')\n",
    "            \n",
    "            self.previous_action = None\n",
    "            self.previous_state = None\n",
    "            \n",
    "            self.move_number = 0\n",
    "            \n",
    "            return actions.FUNCTIONS.no_op()\n",
    "        \n",
    "        if obs.first():\n",
    "            player_y, player_x = (obs.observation.feature_minimap.player_relative == features.PlayerRelative.SELF).nonzero()\n",
    "            self.base_top_left = 1 if player_y.any() and player_y.mean() <= 31 else 0\n",
    "        \n",
    "        ccs = self.get_units_by_type(obs, units.Terran.CommandCenter)\n",
    "        if len(ccs) > 0:\n",
    "            self.cc_x, self.cc_y = self.getMeanLocation(ccs)\n",
    "            \n",
    "        cc_count = len(ccs)\n",
    "        \n",
    "        supply_depot_count = len(self.get_units_by_type(obs, units.Terran.SupplyDepot))\n",
    "\n",
    "        barracks_count = len(self.get_units_by_type(obs, units.Terran.Barracks))\n",
    "\n",
    "        army_supply = obs.observation.player.food_used\n",
    "        \n",
    "        if self.move_number == 0:\n",
    "            self.move_number += 1\n",
    "            \n",
    "            current_state = np.zeros(8)\n",
    "            current_state[0] = cc_count\n",
    "            current_state[1] = supply_depot_count\n",
    "            current_state[2] = barracks_count\n",
    "            current_state[3] = army_supply\n",
    "    \n",
    "            hot_squares = np.zeros(4)        \n",
    "            enemy_y, enemy_x = (obs.observation.feature_minimap.player_relative == features.PlayerRelative.ENEMY).nonzero()\n",
    "            for i in range(0, len(enemy_y)):\n",
    "                y = int(math.ceil((enemy_y[i] + 1) / 32))\n",
    "                x = int(math.ceil((enemy_x[i] + 1) / 32))\n",
    "                \n",
    "                hot_squares[((y - 1) * 2) + (x - 1)] = 1\n",
    "            \n",
    "            if not self.base_top_left:\n",
    "                hot_squares = hot_squares[::-1]\n",
    "            \n",
    "            for i in range(0, 4):\n",
    "                current_state[i + 4] = hot_squares[i]\n",
    "    \n",
    "            if self.previous_action is not None:\n",
    "                self.qlearn.learn(str(self.previous_state), self.previous_action, 0, str(current_state))\n",
    "        \n",
    "            rl_action = self.qlearn.choose_action(str(current_state))\n",
    "\n",
    "            self.previous_state = current_state\n",
    "            self.previous_action = rl_action\n",
    "        \n",
    "            smart_action, x, y = self.splitAction(self.previous_action)\n",
    "            \n",
    "            if smart_action == ACTION_BUILD_BARRACKS or smart_action == ACTION_BUILD_SUPPLY_DEPOT:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_point.id):\n",
    "                    scvs = self.get_units_by_type(obs, units.Terran.SCV)\n",
    "                    if len(scvs) > 0:\n",
    "                        scv = random.choice(scvs)\n",
    "                        if scv.x >= 0 and scv.y >= 0:\n",
    "                            return actions.FUNCTIONS.select_point(\"select\", (scv.x,\n",
    "                                                                              scv.y))\n",
    "                \n",
    "            elif smart_action == ACTION_BUILD_MARINE:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_point.id):\n",
    "                    barracks = self.get_units_by_type(obs, units.Terran.Barracks)\n",
    "                    if len(barracks) > 0:\n",
    "                        barrack = random.choice(barracks)\n",
    "                        if barrack.x >= 0 and barrack.y >= 0:\n",
    "                            return actions.FUNCTIONS.select_point(\"select_all_type\", (barrack.x,\n",
    "                                                                                  barrack.y))\n",
    "                \n",
    "            elif smart_action == ACTION_ATTACK:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_army.id):\n",
    "                    return actions.FUNCTIONS.select_army(\"select\")\n",
    "                \n",
    "        elif self.move_number == 1:\n",
    "            self.move_number += 1\n",
    "            \n",
    "            smart_action, x, y = self.splitAction(self.previous_action)\n",
    "                \n",
    "            if smart_action == ACTION_BUILD_SUPPLY_DEPOT:\n",
    "                if supply_depot_count < 2 and self.can_do(obs, actions.FUNCTIONS.Build_SupplyDepot_screen.id):\n",
    "                    if len(ccs) > 0:\n",
    "                        if supply_depot_count == 0:\n",
    "                            target = self.transformDistance(self.cc_x, -35, self.cc_y, 0)\n",
    "                        elif supply_depot_count == 1:\n",
    "                            target = self.transformDistance(self.cc_x, -25, self.cc_y, -25)\n",
    "    \n",
    "                        return actions.FUNCTIONS.Build_SupplyDepot_screen(\"now\", target) \n",
    "            \n",
    "            elif smart_action == ACTION_BUILD_BARRACKS:\n",
    "                if barracks_count < 2 and self.can_do(obs, actions.FUNCTIONS.Build_Barracks_screen.id):\n",
    "                    if len(ccs) > 0:\n",
    "                        if  barracks_count == 0:\n",
    "                            target = self.transformDistance(self.cc_x, 15, self.cc_y, -9)\n",
    "                        elif  barracks_count == 1:\n",
    "                            target = self.transformDistance(self.cc_x, 15, self.cc_y, 12)\n",
    "    \n",
    "                        return actions.FUNCTIONS.Build_Barracks_screen(\"now\", target)\n",
    "    \n",
    "            elif smart_action == ACTION_BUILD_MARINE:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.Train_Marine_quick.id):\n",
    "                    return actions.FUNCTIONS.Train_Marine_quick(\"queued\")\n",
    "        \n",
    "            elif smart_action == ACTION_ATTACK:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.Attack_minimap.id):\n",
    "                    x_offset = random.randint(-1, 1)\n",
    "                    y_offset = random.randint(-1, 1)\n",
    "                    \n",
    "                    return actions.FUNCTIONS.Attack_minimap(\"now\", self.transformLocation(int(x) + (x_offset * 8), int(y) + (y_offset * 8)))\n",
    "            \n",
    "        elif self.move_number == 2:\n",
    "            self.move_number = 0\n",
    "            \n",
    "            smart_action, x, y = self.splitAction(self.previous_action)\n",
    "                \n",
    "            if smart_action == ACTION_BUILD_BARRACKS or smart_action == ACTION_BUILD_SUPPLY_DEPOT:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.Harvest_Gather_screen.id):\n",
    "                    mfs = self.get_units_by_type(obs, units.Neutral.MineralField)\n",
    "                    mfs = [mf for mf in mfs if abs(mf.x - self.cc_x) + abs(mf.y - self.cc_y) < 30]\n",
    "                    if len(mfs) > 0:\n",
    "                        mf = random.choice(mfs)\n",
    "                        if mf.x >= 0 and mf.y >= 0:\n",
    "                            return actions.FUNCTIONS.Harvest_Gather_screen(\"queued\", (mf.x,mf.y))\n",
    "            \n",
    "        return actions.FUNCTIONS.no_op()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [run code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0908 21:40:06.476608 18160 sc_process.py:135] Launching SC2: D:/InstallGames/Blizzard/StarCraft II\\Versions/Base81102\\SC2_x64.exe -listen 127.0.0.1 -port 19571 -dataDir D:/InstallGames/Blizzard/StarCraft II\\ -tempDir C:\\Users\\ruzun\\AppData\\Local\\Temp\\sc-5bwwl1po\\ -displayMode 0 -windowwidth 640 -windowheight 480 -windowx 50 -windowy 50\n",
      "I0908 21:40:06.480598 18160 remote_controller.py:167] Connecting to: ws://127.0.0.1:19571/sc2api, attempt: 0, running: True\n",
      "I0908 21:40:09.485237 18160 remote_controller.py:167] Connecting to: ws://127.0.0.1:19571/sc2api, attempt: 1, running: True\n",
      "I0908 21:40:12.489244 18160 remote_controller.py:167] Connecting to: ws://127.0.0.1:19571/sc2api, attempt: 2, running: True\n",
      "I0908 21:40:21.954061 18160 sc2_env.py:314] Environment is ready\n",
      "I0908 21:40:21.965031 18160 sc2_env.py:507] Starting episode 1: [terran, terran] on Simple64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0/no_op                                              ()\n",
      "   1/move_camera                                        (1/minimap [64, 64])\n",
      "   2/select_point                                       (6/select_point_act [4]; 0/screen [84, 84])\n",
      "   3/select_rect                                        (7/select_add [2]; 0/screen [84, 84]; 2/screen2 [84, 84])\n",
      "   4/select_control_group                               (4/control_group_act [5]; 5/control_group_id [10])\n",
      " 264/Harvest_Gather_screen                              (3/queued [2]; 0/screen [84, 84])\n",
      "  12/Attack_screen                                      (3/queued [2]; 0/screen [84, 84])\n",
      "  13/Attack_minimap                                     (3/queued [2]; 1/minimap [64, 64])\n",
      " 274/HoldPosition_quick                                 (3/queued [2])\n",
      " 549/Effect_Spray_minimap                               (3/queued [2]; 1/minimap [64, 64])\n",
      " 451/Smart_screen                                       (3/queued [2]; 0/screen [84, 84])\n",
      " 452/Smart_minimap                                      (3/queued [2]; 1/minimap [64, 64])\n",
      " 453/Stop_quick                                         (3/queued [2])\n",
      " 331/Move_screen                                        (3/queued [2]; 0/screen [84, 84])\n",
      " 332/Move_minimap                                       (3/queued [2]; 1/minimap [64, 64])\n",
      " 333/Patrol_screen                                      (3/queued [2]; 0/screen [84, 84])\n",
      " 334/Patrol_minimap                                     (3/queued [2]; 1/minimap [64, 64])\n",
      " 220/Effect_Repair_screen                               (3/queued [2]; 0/screen [84, 84])\n",
      " 221/Effect_Repair_autocast                             ()\n",
      " 230/Effect_Spray_screen                                (3/queued [2]; 0/screen [84, 84])\n",
      " 269/Harvest_Return_quick                               (3/queued [2])\n",
      "  79/Build_Refinery_screen                              (3/queued [2]; 0/screen [84, 84])\n",
      "  91/Build_SupplyDepot_screen                           (3/queued [2]; 0/screen [84, 84])\n",
      " 261/Halt_quick                                         (3/queued [2])\n",
      "  50/Build_EngineeringBay_screen                        (3/queued [2]; 0/screen [84, 84])\n",
      "  42/Build_Barracks_screen                              (3/queued [2]; 0/screen [84, 84])\n",
      "  44/Build_CommandCenter_screen                         (3/queued [2]; 0/screen [84, 84])\n",
      "  43/Build_Bunker_screen                                (3/queued [2]; 0/screen [84, 84])\n",
      "   6/select_idle_worker                                 (10/select_worker [4])\n",
      "   5/select_unit                                        (8/select_unit_act [4]; 9/select_unit_id [500])\n",
      " 140/Cancel_quick                                       (3/queued [2])\n",
      " 335/Rally_Units_screen                                 (3/queued [2]; 0/screen [84, 84])\n",
      " 336/Rally_Units_minimap                                (3/queued [2]; 1/minimap [64, 64])\n",
      " 281/Lift_quick                                         (3/queued [2])\n",
      " 477/Train_Marine_quick                                 (3/queued [2])\n",
      " 168/Cancel_Last_quick                                  (3/queued [2])\n",
      "   7/select_army                                        (7/select_add [2])\n",
      "  11/build_queue                                        (11/build_queue_id [10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0908 21:42:07.988700 18160 sc2_env.py:725] Episode 1 finished after 28560 game steps. Outcome: [-1], reward: [-1], score: [3180]\n",
      "I0908 21:42:11.958553 18160 sc2_env.py:507] Starting episode 2: [terran, terran] on Simple64\n",
      "I0908 21:43:01.295755 18160 sc2_env.py:725] Episode 2 finished after 16504 game steps. Outcome: [1], reward: [1], score: [4435]\n",
      "I0908 21:43:05.039045 18160 sc2_env.py:507] Starting episode 3: [terran, terran] on Simple64\n",
      "I0908 21:43:44.237140 18160 sc2_env.py:725] Episode 3 finished after 12928 game steps. Outcome: [1], reward: [1], score: [5405]\n",
      "I0908 21:43:48.344501 18160 sc2_env.py:507] Starting episode 4: [terran, terran] on Simple64\n",
      "I0908 21:43:48.720548 18160 sc2_env.py:752] Environment Close\n",
      "I0908 21:43:48.822276 18160 sc_process.py:232] Shutdown gracefully.\n",
      "I0908 21:43:48.823274 18160 sc_process.py:210] Shutdown with return code: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 206.756 seconds for 7258 steps: 35.104 fps\n"
     ]
    },
    {
     "ename": "WebSocketProtocolException",
     "evalue": "Illegal frame",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebSocketProtocolException\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-60174cc17dd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\absl\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv, flags_parser)\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m       \u001b[0m_run_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m       \u001b[0musage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\absl\\app.py\u001b[0m in \u001b[0;36m_run_main\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e0ecf125b015>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(unused_argv)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m   \u001b[0mrun_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e0ecf125b015>\u001b[0m in \u001b[0;36mrun_thread\u001b[1;34m(agent_classes, players, map_name, visualize)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0mrun_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_agent_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_episodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_replay\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m       \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_replay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munused_argv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\env\\base_env_wrapper.py\u001b[0m in \u001b[0;36msave_replay\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_replay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_replay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\env\\sc2_env.py\u001b[0m in \u001b[0;36msave_replay\u001b[1;34m(self, replay_dir, prefix)\u001b[0m\n\u001b[0;32m    745\u001b[0m       \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     replay_path = self._run_config.save_replay(\n\u001b[1;32m--> 747\u001b[1;33m         self._controllers[0].save_replay(), replay_dir, prefix)\n\u001b[0m\u001b[0;32m    748\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrote replay to: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplay_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreplay_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\remote_controller.py\u001b[0m in \u001b[0;36m_valid_status\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \"`%s` called while in state: %s, valid: (%s)\" % (\n\u001b[0;32m     98\u001b[0m                 func.__name__, self.status, \",\".join(map(str, valid))))\n\u001b[1;32m---> 99\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_valid_status\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\stopwatch.py\u001b[0m in \u001b[0;36m_stopwatch\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0m_stopwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_stopwatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\remote_controller.py\u001b[0m in \u001b[0;36msave_replay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_replay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;34m\"\"\"Save a replay, returning the data.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_replay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msc_pb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequestSaveReplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m       \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_req\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error during %s: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36msend_req\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;34m\"\"\"Write a pre-filled Request and return the Response.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\stopwatch.py\u001b[0m in \u001b[0;36m_stopwatch\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0m_stopwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_stopwatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 self._port)\n\u001b[0;32m    101\u001b[0m       \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc2_verbose_protocol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m       self._log(\"-------------- [%s] Read %s in %0.1f msec --------------\\n%s\",\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"read_response\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mcatch_websocket_connection_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mresponse_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresponse_str\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mProtocolError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Got an empty response from SC2.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_core.py\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \"\"\"\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mopcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mopcode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_TEXT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_core.py\u001b[0m in \u001b[0;36mrecv_data\u001b[1;34m(self, control_frame)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mreturn\u001b[0m  \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[0mopcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_data_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mopcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_core.py\u001b[0m in \u001b[0;36mrecv_data_frame\u001b[1;34m(self, control_frame)\u001b[0m\n\u001b[0;32m    349\u001b[0m                     \"Not a valid frame %s\" % frame)\n\u001b[0;32m    350\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopcode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_TEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_BINARY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_CONT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcont_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcont_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_abnf.py\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecving_frames\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopcode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_CONT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mWebSocketProtocolException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Illegal frame\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecving_frames\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m                 \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopcode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_TEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_BINARY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebSocketProtocolException\u001b[0m: Illegal frame"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Refining \n",
    "- Ignoreing Learing When State Does Not Change : 'Maximization Bias in RL' Problem\n",
    "- Preventing Invalid Actions\n",
    "- Adding Our Unit Locations to the State\n",
    "\n",
    "![Winning rate graph](./images/rlagent_with_sparse_reward_learning_scoreTerran-Terran-350_Eps.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import pickle\n",
    "\n",
    "from pysc2.agents import base_agent\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions, features, units\n",
    "from absl import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'rlagent_with_sparse_reward_learning_data'\n",
    "SCORE_FILE = 'rlagent_with_sparse_reward_learning_score'\n",
    "\n",
    "ACTION_DO_NOTHING = 'donothing'\n",
    "ACTION_BUILD_SUPPLY_DEPOT = 'buildsupplydepot'\n",
    "ACTION_BUILD_BARRACKS = 'buildbarracks'\n",
    "ACTION_BUILD_MARINE = 'buildmarine'\n",
    "ACTION_ATTACK = 'attack'\n",
    "\n",
    "smart_actions = [\n",
    "    ACTION_DO_NOTHING,\n",
    "    ACTION_BUILD_SUPPLY_DEPOT,\n",
    "    ACTION_BUILD_BARRACKS,\n",
    "    ACTION_BUILD_MARINE,\n",
    "]\n",
    "\n",
    "for mm_x in range(0, 64):\n",
    "    for mm_y in range(0, 64):\n",
    "        if (mm_x + 1) % 32 == 0 and (mm_y + 1) % 32 == 0:\n",
    "            smart_actions.append(ACTION_ATTACK + '_' + str(mm_x - 16) + '_' + str(mm_y - 16))\n",
    "            \n",
    "scores = []                        # list containing scores from each episode\n",
    "scores_window = deque(maxlen=100)  # last 100 scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫째, Ignoreing Learing When State Does Not Change : 'Maximization Bias in RL' Problem 해결 방법\n",
    "#### 학습의 초기과정에서 같은 State에 자주 도착하는 경우 덜 가치있는 Action을 가장 가치있는 Action으로 밀어 붙이는 경향이 생깁니다. 이 것이 반복되면 시간이 지남에 따라 완전히 다른 State 대신 동일한 State에 더 자주 도착하면 모든 보상이 0에 가까워 지는 문제가 생긴다.\n",
    "\n",
    "#### 이를 해결하기 위해 아래와 같이 간단한 방법을 추가함.\n",
    "\n",
    "    def learn(self, s, a, r, s_):\n",
    "        if s == s_:\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 둘째, Preventing Invalid Actions\n",
    "\n",
    "< Invalid Actions 의 예>\n",
    "- supply depot 제한 갯수 2에 도달했거나 supply depot를 건설할 SCV가 없는 경우 에이전트가 supply depot를 건설 할 수 없도로 한다.\n",
    "- supply depot가 없거나 barrack 제한 갯수 2에 도달했거나 barrack 제한 갯수를 지을 SCV이 없다면 에이전트가 barrack를 지을 수 없도록 한다.\n",
    "- barrack가 없거나 supply limit에 도달한 경우 marine을 훈련시키지 않는다.\n",
    "\n",
    "#### 학습과정에서 에이전트가 Invalid Actions을 시도하는 것이 반복적으로 관찰됩니다. 사용가능한 Action의 수가 Available Actions 절반인 경우가 많기 때문에 에이전트는 불필요한 Action에서 학습하는 데 시간을 많이 보내게 됩니다.\n",
    "#### 이러한 Invalid Actions을 필터링하여 에이전트가 State 변경으로 이어지는 Action을 시도하는 데 집중하도록하여 Exploration을 줄이고 학습 시간을 개선 할 수 있습니다.\n",
    "\n",
    "#### 이를 해결하기 위해 아래와 같이 self.disallowed_actions 와 excluded_action 을 활용하는 방법을 추가함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셋째, Adding Our Unit Locations to the State\n",
    "\n",
    "#### \"아군이 어디에 있는지 모른다면 어떤 위치가 공격하기에 가장 좋은지 알 수 있지 않을까요?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference from https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow\n",
    "class QLearningTable:\n",
    "    def __init__(self, actions, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9):\n",
    "        self.actions = actions  # a list\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon = e_greedy\n",
    "        self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64)\n",
    "        self.disallowed_actions = {}\n",
    "        \n",
    "    def choose_action(self, observation, excluded_actions=[]):\n",
    "        self.check_state_exist(observation)\n",
    "        \n",
    "        self.disallowed_actions[observation] = excluded_actions\n",
    "        \n",
    "        #state_action = self.q_table.ix[observation, :]\n",
    "        #state_action = self.q_table.loc[observation, self.q_table.columns[:]]\n",
    "        state_action = self.q_table.loc[observation, :]\n",
    "        \n",
    "        for excluded_action in excluded_actions:\n",
    "            del state_action[excluded_action]\n",
    "        \n",
    "        if np.random.uniform() < self.epsilon:            \n",
    "            # some actions have the same value\n",
    "            state_action = state_action.reindex(np.random.permutation(state_action.index))\n",
    "            \n",
    "            action = state_action.idxmax()\n",
    "        else:\n",
    "            # choose random action\n",
    "            action = np.random.choice(state_action.index)\n",
    "            \n",
    "        return action\n",
    "\n",
    "    def learn(self, s, a, r, s_):\n",
    "        if s == s_:\n",
    "            return\n",
    "        \n",
    "        self.check_state_exist(s_)\n",
    "        self.check_state_exist(s)\n",
    "        \n",
    "        #q_predict = self.q_table.ix[s, a]\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        \n",
    "        #s_rewards = self.q_table.ix[s_, :]\n",
    "        #s_rewards = self.q_table.loc[s_, self.q_table.columns[:]]\n",
    "        s_rewards = self.q_table.loc[s_, :]\n",
    "        \n",
    "        if s_ in self.disallowed_actions:\n",
    "            for excluded_action in self.disallowed_actions[s_]:\n",
    "                del s_rewards[excluded_action]\n",
    "        \n",
    "        if s_ != 'terminal':\n",
    "            q_target = r + self.gamma * s_rewards.max()\n",
    "        else:\n",
    "            q_target = r  # next state is terminal\n",
    "            \n",
    "        # update\n",
    "        #self.q_table.ix[s, a] += self.lr * (q_target - q_predict)\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)\n",
    "\n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            # append new state to q table\n",
    "            self.q_table = self.q_table.append(pd.Series([0] * len(self.actions), index=self.q_table.columns, name=state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerranSparseRewardRLAgent(base_agent.BaseAgent):\n",
    "    def __init__(self):\n",
    "        super(TerranSparseRewardRLAgent, self).__init__()\n",
    "        \n",
    "        self.qlearn = QLearningTable(actions=list(range(len(smart_actions))))\n",
    "        \n",
    "        self.previous_action = None\n",
    "        self.previous_state = None\n",
    "        \n",
    "        self.cc_y = None\n",
    "        self.cc_x = None\n",
    "        \n",
    "        self.move_number = 0\n",
    "        \n",
    "        if os.path.isfile(DATA_FILE + '.gz'):\n",
    "            self.qlearn.q_table = pd.read_pickle(DATA_FILE + '.gz', compression='gzip')\n",
    "\n",
    "    def transformDistance(self, x, x_distance, y, y_distance):\n",
    "        if not self.base_top_left:\n",
    "            return [x - x_distance, y - y_distance]\n",
    "        \n",
    "        return [x + x_distance, y + y_distance]\n",
    "    \n",
    "    def transformLocation(self, x, y):\n",
    "        if not self.base_top_left:\n",
    "            return [64 - x, 64 - y]\n",
    "        \n",
    "        return [x, y]\n",
    "    \n",
    "    def getMeanLocation(self, unitList):\n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        for unit in unitList:\n",
    "            sum_x += unit.x\n",
    "            sum_y += unit.y\n",
    "        mean_x = sum_x / len(unitList)\n",
    "        mean_y = sum_y / len(unitList)\n",
    "        \n",
    "        return [mean_x, mean_y]\n",
    "    \n",
    "    def splitAction(self, action_id):\n",
    "        smart_action = smart_actions[action_id]\n",
    "            \n",
    "        x = 0\n",
    "        y = 0\n",
    "        if '_' in smart_action:\n",
    "            smart_action, x, y = smart_action.split('_')\n",
    "\n",
    "        return (smart_action, x, y)\n",
    "    \n",
    "    def unit_type_is_selected(self, obs, unit_type):\n",
    "        if (len(obs.observation.single_select) > 0 and\n",
    "            obs.observation.single_select[0].unit_type == unit_type):\n",
    "              return True\n",
    "\n",
    "        if (len(obs.observation.multi_select) > 0 and\n",
    "            obs.observation.multi_select[0].unit_type == unit_type):\n",
    "              return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_units_by_type(self, obs, unit_type):\n",
    "        return [unit for unit in obs.observation.feature_units\n",
    "                if unit.unit_type == unit_type]\n",
    "\n",
    "    def can_do(self, obs, action):\n",
    "        return action in obs.observation.available_actions\n",
    "        \n",
    "    def step(self, obs):\n",
    "        super(TerranSparseRewardRLAgent, self).step(obs)\n",
    "\n",
    "        #time.sleep(0.5)\n",
    "        \n",
    "        if obs.last():\n",
    "            reward = obs.reward\n",
    "        \n",
    "            self.qlearn.learn(str(self.previous_state), self.previous_action, reward, 'terminal')\n",
    "            \n",
    "            self.qlearn.q_table.to_pickle(DATA_FILE + '.gz', 'gzip')\n",
    "            \n",
    "            scores_window.append(obs.reward)  # save most recent reward\n",
    "            win_rate = scores_window.count(1)/len(scores_window)*100\n",
    "            tie_rate = scores_window.count(0)/len(scores_window)*100\n",
    "            lost_rate = scores_window.count(-1)/len(scores_window)*100\n",
    "            \n",
    "            scores.append([win_rate, tie_rate, lost_rate])  # save most recent score(win_rate, tie_rate, lost_rate)\n",
    "            with open(SCORE_FILE + '.txt', \"wb\") as fp:\n",
    "                pickle.dump(scores, fp)\n",
    "            \n",
    "            self.previous_action = None\n",
    "            self.previous_state = None\n",
    "            \n",
    "            self.move_number = 0\n",
    "            \n",
    "            return actions.FUNCTIONS.no_op()\n",
    "        \n",
    "        if obs.first():\n",
    "            player_y, player_x = (obs.observation.feature_minimap.player_relative == features.PlayerRelative.SELF).nonzero()\n",
    "            self.base_top_left = 1 if player_y.any() and player_y.mean() <= 31 else 0\n",
    "        \n",
    "        ccs = self.get_units_by_type(obs, units.Terran.CommandCenter)\n",
    "        if len(ccs) > 0:\n",
    "            self.cc_x, self.cc_y = self.getMeanLocation(ccs)\n",
    "            \n",
    "        cc_count = len(ccs)\n",
    "        \n",
    "        supply_depot_count = len(self.get_units_by_type(obs, units.Terran.SupplyDepot))\n",
    "\n",
    "        barracks_count = len(self.get_units_by_type(obs, units.Terran.Barracks))\n",
    "        \n",
    "        supply_used = obs.observation.player.food_used\n",
    "        supply_limit = obs.observation.player.food_cap\n",
    "        army_supply = obs.observation.player.food_army\n",
    "        worker_supply = obs.observation.player.food_workers\n",
    "        \n",
    "        supply_free = supply_limit - supply_used\n",
    "        \n",
    "        if self.move_number == 0:\n",
    "            self.move_number += 1\n",
    "            \n",
    "            \n",
    "            current_state = np.zeros(12)\n",
    "            current_state[0] = cc_count\n",
    "            current_state[1] = supply_depot_count\n",
    "            current_state[2] = barracks_count\n",
    "            current_state[3] = army_supply\n",
    "    \n",
    "            hot_squares = np.zeros(4)        \n",
    "            enemy_y, enemy_x = (obs.observation.feature_minimap.player_relative == features.PlayerRelative.ENEMY).nonzero()\n",
    "            for i in range(0, len(enemy_y)):\n",
    "                y = int(math.ceil((enemy_y[i] + 1) / 32))\n",
    "                x = int(math.ceil((enemy_x[i] + 1) / 32))\n",
    "                \n",
    "                hot_squares[((y - 1) * 2) + (x - 1)] = 1\n",
    "            \n",
    "            if not self.base_top_left:\n",
    "                hot_squares = hot_squares[::-1]\n",
    "            \n",
    "            for i in range(0, 4):\n",
    "                current_state[i + 4] = hot_squares[i]\n",
    "                \n",
    "            green_squares = np.zeros(4)        \n",
    "            friendly_y, friendly_x = (obs.observation.feature_minimap.player_relative == features.PlayerRelative.SELF).nonzero()\n",
    "            for i in range(0, len(friendly_y)):\n",
    "                y = int(math.ceil((friendly_y[i] + 1) / 32))\n",
    "                x = int(math.ceil((friendly_x[i] + 1) / 32))\n",
    "                \n",
    "                green_squares[((y - 1) * 2) + (x - 1)] = 1\n",
    "            \n",
    "            if not self.base_top_left:\n",
    "                green_squares = green_squares[::-1]\n",
    "            \n",
    "            for i in range(0, 4):\n",
    "                current_state[i + 8] = green_squares[i]\n",
    "    \n",
    "            if self.previous_action is not None:\n",
    "                self.qlearn.learn(str(self.previous_state), self.previous_action, 0, str(current_state))\n",
    "        \n",
    "            excluded_actions = []\n",
    "            if supply_depot_count == 2 or worker_supply == 0:\n",
    "                excluded_actions.append(1)\n",
    "                \n",
    "            if supply_depot_count == 0 or barracks_count == 2 or worker_supply == 0:\n",
    "                excluded_actions.append(2)\n",
    "\n",
    "            if supply_free == 0 or barracks_count == 0:\n",
    "                excluded_actions.append(3)\n",
    "                \n",
    "            if army_supply == 0:\n",
    "                excluded_actions.append(4)\n",
    "                excluded_actions.append(5)\n",
    "                excluded_actions.append(6)\n",
    "                excluded_actions.append(7)\n",
    "        \n",
    "            rl_action = self.qlearn.choose_action(str(current_state), excluded_actions)\n",
    "\n",
    "            self.previous_state = current_state\n",
    "            self.previous_action = rl_action\n",
    "        \n",
    "            smart_action, x, y = self.splitAction(self.previous_action)\n",
    "            \n",
    "            if smart_action == ACTION_BUILD_BARRACKS or smart_action == ACTION_BUILD_SUPPLY_DEPOT:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_point.id):\n",
    "                    scvs = self.get_units_by_type(obs, units.Terran.SCV)\n",
    "                    if len(scvs) > 0:\n",
    "                        scv = random.choice(scvs)\n",
    "                        if scv.x >= 0 and scv.y >= 0:\n",
    "                            return actions.FUNCTIONS.select_point(\"select\", (scv.x,\n",
    "                                                                              scv.y))\n",
    "                \n",
    "            elif smart_action == ACTION_BUILD_MARINE:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_point.id):\n",
    "                    barracks = self.get_units_by_type(obs, units.Terran.Barracks)\n",
    "                    if len(barracks) > 0:\n",
    "                        barrack = random.choice(barracks)\n",
    "                        if barrack.x >= 0 and barrack.y >= 0:\n",
    "                            return actions.FUNCTIONS.select_point(\"select_all_type\", (barrack.x,\n",
    "                                                                                  barrack.y))\n",
    "                \n",
    "            elif smart_action == ACTION_ATTACK:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.select_army.id):\n",
    "                    return actions.FUNCTIONS.select_army(\"select\")\n",
    "                \n",
    "        elif self.move_number == 1:\n",
    "            self.move_number += 1\n",
    "            \n",
    "            smart_action, x, y = self.splitAction(self.previous_action)\n",
    "                \n",
    "            if smart_action == ACTION_BUILD_SUPPLY_DEPOT:\n",
    "                if supply_depot_count < 2 and self.can_do(obs, actions.FUNCTIONS.Build_SupplyDepot_screen.id):\n",
    "                    if len(ccs) > 0:\n",
    "                        if supply_depot_count == 0:\n",
    "                            target = self.transformDistance(self.cc_x, -35, self.cc_y, 0)\n",
    "                        elif supply_depot_count == 1:\n",
    "                            target = self.transformDistance(self.cc_x, -25, self.cc_y, -25)\n",
    "    \n",
    "                        return actions.FUNCTIONS.Build_SupplyDepot_screen(\"now\", target) \n",
    "            \n",
    "            elif smart_action == ACTION_BUILD_BARRACKS:\n",
    "                if barracks_count < 2 and self.can_do(obs, actions.FUNCTIONS.Build_Barracks_screen.id):\n",
    "                    if len(ccs) > 0:\n",
    "                        if  barracks_count == 0:\n",
    "                            target = self.transformDistance(self.cc_x, 15, self.cc_y, -9)\n",
    "                        elif  barracks_count == 1:\n",
    "                            target = self.transformDistance(self.cc_x, 15, self.cc_y, 12)\n",
    "    \n",
    "                        return actions.FUNCTIONS.Build_Barracks_screen(\"now\", target)\n",
    "    \n",
    "            elif smart_action == ACTION_BUILD_MARINE:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.Train_Marine_quick.id):\n",
    "                    return actions.FUNCTIONS.Train_Marine_quick(\"queued\")\n",
    "        \n",
    "            elif smart_action == ACTION_ATTACK:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.Attack_minimap.id):\n",
    "                    x_offset = random.randint(-1, 1)\n",
    "                    y_offset = random.randint(-1, 1)\n",
    "                    \n",
    "                    return actions.FUNCTIONS.Attack_minimap(\"now\", self.transformLocation(int(x) + (x_offset * 8), int(y) + (y_offset * 8)))\n",
    "            \n",
    "        elif self.move_number == 2:\n",
    "            self.move_number = 0\n",
    "            \n",
    "            smart_action, x, y = self.splitAction(self.previous_action)\n",
    "                \n",
    "            if smart_action == ACTION_BUILD_BARRACKS or smart_action == ACTION_BUILD_SUPPLY_DEPOT:\n",
    "                if self.can_do(obs, actions.FUNCTIONS.Harvest_Gather_screen.id):\n",
    "                    mfs = self.get_units_by_type(obs, units.Neutral.MineralField)\n",
    "                    if len(mfs) > 0:\n",
    "                        mf = random.choice(mfs)\n",
    "                        if mf.x >= 0 and mf.y >= 0:\n",
    "                            return actions.FUNCTIONS.Harvest_Gather_screen(\"queued\", (mf.x,mf.y))\n",
    "            \n",
    "        return actions.FUNCTIONS.no_op()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [run code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0908 21:43:53.460419 18160 sc_process.py:135] Launching SC2: D:/InstallGames/Blizzard/StarCraft II\\Versions/Base81102\\SC2_x64.exe -listen 127.0.0.1 -port 24684 -dataDir D:/InstallGames/Blizzard/StarCraft II\\ -tempDir C:\\Users\\ruzun\\AppData\\Local\\Temp\\sc-q7m334zy\\ -displayMode 0 -windowwidth 640 -windowheight 480 -windowx 50 -windowy 50\n",
      "I0908 21:43:53.464408 18160 remote_controller.py:167] Connecting to: ws://127.0.0.1:24684/sc2api, attempt: 0, running: True\n",
      "I0908 21:43:56.483856 18160 remote_controller.py:167] Connecting to: ws://127.0.0.1:24684/sc2api, attempt: 1, running: True\n",
      "I0908 21:43:59.489368 18160 remote_controller.py:167] Connecting to: ws://127.0.0.1:24684/sc2api, attempt: 2, running: True\n",
      "I0908 21:44:10.662966 18160 sc2_env.py:314] Environment is ready\n",
      "I0908 21:44:10.674935 18160 sc2_env.py:507] Starting episode 1: [terran, terran] on Simple64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0/no_op                                              ()\n",
      "   1/move_camera                                        (1/minimap [64, 64])\n",
      "   2/select_point                                       (6/select_point_act [4]; 0/screen [84, 84])\n",
      "   3/select_rect                                        (7/select_add [2]; 0/screen [84, 84]; 2/screen2 [84, 84])\n",
      "   4/select_control_group                               (4/control_group_act [5]; 5/control_group_id [10])\n",
      " 264/Harvest_Gather_screen                              (3/queued [2]; 0/screen [84, 84])\n",
      "  12/Attack_screen                                      (3/queued [2]; 0/screen [84, 84])\n",
      "  13/Attack_minimap                                     (3/queued [2]; 1/minimap [64, 64])\n",
      " 274/HoldPosition_quick                                 (3/queued [2])\n",
      " 549/Effect_Spray_minimap                               (3/queued [2]; 1/minimap [64, 64])\n",
      " 451/Smart_screen                                       (3/queued [2]; 0/screen [84, 84])\n",
      " 452/Smart_minimap                                      (3/queued [2]; 1/minimap [64, 64])\n",
      " 453/Stop_quick                                         (3/queued [2])\n",
      " 331/Move_screen                                        (3/queued [2]; 0/screen [84, 84])\n",
      " 332/Move_minimap                                       (3/queued [2]; 1/minimap [64, 64])\n",
      " 333/Patrol_screen                                      (3/queued [2]; 0/screen [84, 84])\n",
      " 334/Patrol_minimap                                     (3/queued [2]; 1/minimap [64, 64])\n",
      " 220/Effect_Repair_screen                               (3/queued [2]; 0/screen [84, 84])\n",
      " 221/Effect_Repair_autocast                             ()\n",
      " 230/Effect_Spray_screen                                (3/queued [2]; 0/screen [84, 84])\n",
      " 269/Harvest_Return_quick                               (3/queued [2])\n",
      "  79/Build_Refinery_screen                              (3/queued [2]; 0/screen [84, 84])\n",
      "  91/Build_SupplyDepot_screen                           (3/queued [2]; 0/screen [84, 84])\n",
      " 261/Halt_quick                                         (3/queued [2])\n",
      "  50/Build_EngineeringBay_screen                        (3/queued [2]; 0/screen [84, 84])\n",
      "  42/Build_Barracks_screen                              (3/queued [2]; 0/screen [84, 84])\n",
      " 140/Cancel_quick                                       (3/queued [2])\n",
      " 335/Rally_Units_screen                                 (3/queued [2]; 0/screen [84, 84])\n",
      " 336/Rally_Units_minimap                                (3/queued [2]; 1/minimap [64, 64])\n",
      "   5/select_unit                                        (8/select_unit_act [4]; 9/select_unit_id [500])\n",
      " 281/Lift_quick                                         (3/queued [2])\n",
      " 477/Train_Marine_quick                                 (3/queued [2])\n",
      " 168/Cancel_Last_quick                                  (3/queued [2])\n",
      "   7/select_army                                        (7/select_add [2])\n",
      "  11/build_queue                                        (11/build_queue_id [10])\n",
      "  43/Build_Bunker_screen                                (3/queued [2]; 0/screen [84, 84])\n",
      "  44/Build_CommandCenter_screen                         (3/queued [2]; 0/screen [84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0908 21:45:37.080710 18160 sc2_env.py:725] Episode 1 finished after 26104 game steps. Outcome: [-1], reward: [-1], score: [6745]\n",
      "I0908 21:45:40.971466 18160 sc2_env.py:507] Starting episode 2: [terran, terran] on Simple64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/select_idle_worker                                 (10/select_worker [4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0908 21:47:07.113383 18160 sc2_env.py:725] Episode 2 finished after 24712 game steps. Outcome: [-1], reward: [-1], score: [7635]\n",
      "I0908 21:47:11.392599 18160 sc2_env.py:507] Starting episode 3: [terran, terran] on Simple64\n",
      "I0908 21:48:28.862629 18160 sc2_env.py:725] Episode 3 finished after 23152 game steps. Outcome: [-1], reward: [-1], score: [6155]\n",
      "I0908 21:48:32.767617 18160 sc2_env.py:507] Starting episode 4: [terran, terran] on Simple64\n",
      "I0908 21:48:43.116803 18160 sc2_env.py:725] Episode 4 finished after 3921 game steps. Outcome: [-1], reward: [-1], score: [2605]\n",
      "I0908 21:48:44.346657 18160 sc2_env.py:752] Environment Close\n",
      "I0908 21:48:44.448358 18160 sc_process.py:232] Shutdown gracefully.\n",
      "I0908 21:48:44.449356 18160 sc_process.py:210] Shutdown with return code: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 273.672 seconds for 9741 steps: 35.594 fps\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "Error during create_game: Connection already closed. SC2 probably crashed. Check the error log.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebSocketConnectionClosedException\u001b[0m        Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36mcatch_websocket_connection_errors\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mwebsocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWebSocketConnectionClosedException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mcatch_websocket_connection_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mresponse_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresponse_str\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_core.py\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mopcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mopcode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mABNF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPCODE_TEXT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_core.py\u001b[0m in \u001b[0;36mrecv_data\u001b[1;34m(self, control_frame)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[0mopcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_data_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mopcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_core.py\u001b[0m in \u001b[0;36mrecv_data_frame\u001b[1;34m(self, control_frame)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_core.py\u001b[0m in \u001b[0;36mrecv_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    377\u001b[0m         \"\"\"\n\u001b[1;32m--> 378\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_abnf.py\u001b[0m in \u001b[0;36mrecv_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_received_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsv3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhas_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_abnf.py\u001b[0m in \u001b[0;36mrecv_header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrecv_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_strict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_abnf.py\u001b[0m in \u001b[0;36mrecv_strict\u001b[1;34m(self, bufsize)\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[1;31m# fragmentation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             \u001b[0mbytes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16384\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshortage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_core.py\u001b[0m in \u001b[0;36m_recv\u001b[1;34m(self, bufsize)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mWebSocketConnectionClosedException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\websocket\\_socket.py\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(sock, bufsize)\u001b[0m\n\u001b[0;32m    114\u001b[0m         raise WebSocketConnectionClosedException(\n\u001b[1;32m--> 115\u001b[1;33m             \"Connection is already closed.\")\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebSocketConnectionClosedException\u001b[0m: Connection is already closed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m       \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_req\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36msend_req\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\stopwatch.py\u001b[0m in \u001b[0;36m_stopwatch\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_stopwatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m       \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc2_verbose_protocol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mcatch_websocket_connection_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mresponse_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresponse_str\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36mcatch_websocket_connection_errors\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mwebsocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWebSocketConnectionClosedException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     raise ConnectionError(\"Connection already closed. SC2 probably crashed. \"\n\u001b[0m\u001b[0;32m     69\u001b[0m                           \"Check the error log.\")\n",
      "\u001b[1;31mConnectionError\u001b[0m: Connection already closed. SC2 probably crashed. Check the error log.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-60174cc17dd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\absl\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv, flags_parser)\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m       \u001b[0m_run_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m       \u001b[0musage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\absl\\app.py\u001b[0m in \u001b[0;36m_run_main\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e0ecf125b015>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(unused_argv)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m   \u001b[0mrun_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e0ecf125b015>\u001b[0m in \u001b[0;36mrun_thread\u001b[1;34m(agent_classes, players, map_name, visualize)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavailable_actions_printer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAvailableActionsPrinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0magents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0magent_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0magent_cls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0magent_classes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m     \u001b[0mrun_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_agent_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_episodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_replay\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m       \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_replay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\env\\run_loop.py\u001b[0m in \u001b[0;36mrun_loop\u001b[1;34m(agents, env, max_frames, max_episodes)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmax_episodes\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtotal_episodes\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_episodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m       \u001b[0mtotal_episodes\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m       \u001b[0mtimesteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0magents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\env\\base_env_wrapper.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\stopwatch.py\u001b[0m in \u001b[0;36m_stopwatch\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0m_stopwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_stopwatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\env\\sc2_env.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_episode_count\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m       \u001b[1;31m# No need to restart for the first episode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_episode_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\env\\sc2_env.py\u001b[0m in \u001b[0;36m_restart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    491\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_controllers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parallel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleave\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_controllers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_join\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0msw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\env\\sc2_env.py\u001b[0m in \u001b[0;36m_create_join\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msc_pb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mComputer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m             difficulty=p.difficulty, ai_build=random.choice(p.build))\n\u001b[1;32m--> 412\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_controllers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_game\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;31m# Create the join requests.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\remote_controller.py\u001b[0m in \u001b[0;36m_valid_status\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \"`%s` called while in state: %s, valid: (%s)\" % (\n\u001b[0;32m     98\u001b[0m                 func.__name__, self.status, \",\".join(map(str, valid))))\n\u001b[1;32m---> 99\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_valid_status\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\remote_controller.py\u001b[0m in \u001b[0;36m_check_error\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_enum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_check_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\stopwatch.py\u001b[0m in \u001b[0;36m_stopwatch\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0m_stopwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_stopwatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\remote_controller.py\u001b[0m in \u001b[0;36mcreate_game\u001b[1;34m(self, req_create_game)\u001b[0m\n\u001b[0;32m    192\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcreate_game\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq_create_game\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;34m\"\"\"Create a new game. This can only be done by the host.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_game\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreq_create_game\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mvalid_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunched\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_game\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysc2\\lib\\protocol.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m       \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_req\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error during %s: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHasField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       raise ConnectionError(\n",
      "\u001b[1;31mConnectionError\u001b[0m: Error during create_game: Connection already closed. SC2 probably crashed. Check the error log."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Winning rate graph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "SCORE_FILE = 'rlagent_with_sparse_reward_learning_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rlagent_with_sparse_reward_learning_score.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-45e96ef741f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSCORE_FILE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rlagent_with_sparse_reward_learning_score.txt'"
     ]
    }
   ],
   "source": [
    "with open(SCORE_FILE + '.txt', \"rb\") as fp:\n",
    "    scores = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_scores = np.array(scores)\n",
    "np_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(np_scores)), np_scores.T[0], color='r', label='win rate')\n",
    "plt.plot(np.arange(len(np_scores)), np_scores.T[1], color='g', label='tie rate')\n",
    "plt.plot(np.arange(len(np_scores)), np_scores.T[2], color='b', label='lose rate')\n",
    "plt.ylabel('Score %')\n",
    "plt.xlabel('Episode #')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starcraft2",
   "language": "python",
   "name": "starcraft2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
